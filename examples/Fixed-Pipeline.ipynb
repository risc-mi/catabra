{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688ef7c7",
   "metadata": {},
   "source": [
    "# Specify Fixed ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ffac0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa31185",
   "metadata": {},
   "source": [
    "This notebook is part of the [CaTabRa GitHub repository](https://github.com/risc-mi/catabra)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670b59f",
   "metadata": {},
   "source": [
    "This short example illustrates how a fixed ML pipeline can be specified in CaTabRa, i.e.,\n",
    "* [how it can be composed](#Compose-Pipeline),\n",
    "* [how it can be utilized in CaTabRa's data analysis workflow](#Utilize-Pipeline), and\n",
    "* [how it can be configured](#Configure-Pipeline).\n",
    "\n",
    "Fixed pipelines (without hyperparameter optimization) can be useful for quickly training and evaluating *baseline models*, like simple logistic regression.\n",
    "\n",
    "For the related question of how to add a new full-fledged AutoML backend (with hyperparameter optimization), or extend the default auto-sklearn backend, refer to [this example](https://github.com/risc-mi/catabra/tree/main/examples/AutoML-Extension.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6454a0",
   "metadata": {},
   "source": [
    "## Compose Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067938a9",
   "metadata": {},
   "source": [
    "We compose a simple pipeline, consisting of elementary preprocessing steps (scaling, imputation) followed by a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19803462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6449030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing pipeline\n",
    "preprocessing = make_pipeline(\n",
    "    MinMaxScaler(),                                      # min-max scale all features to [0, 1] interval\n",
    "    SimpleImputer(strategy='constant', fill_value=-1),   # impute missing values with -1\n",
    "    'passthrough'                                        # no estimator in preprocessing pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0808f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final estimator\n",
    "estimator = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52b48e",
   "metadata": {},
   "source": [
    "**NOTE**: `catabra.automl.fixed_pipeline.standard_preprocessing()` is a convenient built-in implementation of the above preprocessing pipeline. In addition, it also one-hot encodes categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02252b09",
   "metadata": {},
   "source": [
    "We can now register the fixed pipeline as a new AutoML backend (strictly speaking, the term \"AutoML\" is not appropriate in this case, but never mind):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5844b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catabra.automl import fixed_pipeline\n",
    "\n",
    "fixed_pipeline.register_backend(\n",
    "    'logreg',\n",
    "    preprocessing=preprocessing,\n",
    "    estimator=estimator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a892ad",
   "metadata": {},
   "source": [
    "**NOTE**: The `preprocessing` object must implement `fit_transform()` and `transform()`, and the `estimator` object must implement `fit()`, `predict()` and, if used for classification, `predict_proba()`. Both should subclass [`sklearn.base.BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) to be able to get/set hyperparameters with `get_params()` and `set_params()`, respectively. `preprocessing` is optional and can be set to `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61c7e8",
   "metadata": {},
   "source": [
    "## Utilize Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6440598",
   "metadata": {},
   "source": [
    "`\"logreg\"` can be used in [CaTabRa's data analysis workflow](https://github.com/risc-mi/catabra/tree/main/examples/Workflow.ipynb) just as any other AutoML backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cc6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa3d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target labels to DataFrame\n",
    "X['diagnosis'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "430dcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train- and test set by adding column with corresponding values\n",
    "# the name of the column is arbitrary; CaTabRa tries to \"guess\" which samples belong to which set based on the column name and -values\n",
    "X['train'] = X.index <= 0.8 * len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3702f",
   "metadata": {},
   "source": [
    "When analyzing the data, we inform CaTabRa that we want to use the `\"logreg\"` backend by adjusting the config dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ab35bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Analysis started at 2023-03-08 14:34:44.562167\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend logreg for binary_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CaTabRa warning] Could not set number of jobs of Pipeline preprocessing to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 1\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type BinsDetector\n",
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-03-08 14:34:45.339168\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:00.777001\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/logreg_example\n",
      "[CaTabRa] ### Evaluation started at 2023-03-08 14:34:45.385179\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    accuracy @ 0.5: 0.9758771929824561\n",
      "    roc_auc: 0.9944444444444445\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    accuracy @ 0.5: 0.9734513274336283\n",
      "    roc_auc: 0.9991158267020337\n",
      "[CaTabRa] ### Evaluation finished at 2023-03-08 14:34:50.289666\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:04.904487\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/logreg_example/eval\n"
     ]
    }
   ],
   "source": [
    "from catabra.analysis import analyze\n",
    "\n",
    "analyze(\n",
    "    X,\n",
    "    classify='diagnosis',     # name of column containing classification target\n",
    "    split='train',            # name of column containing information about the train-test split (optional)\n",
    "    time=None,                # specifying a time budget has no effect on fixed pipelines\n",
    "    out='logreg_example',\n",
    "    config={\n",
    "        'automl': 'logreg',   # name of the \"AutoML\" backend (in this case it's a fixed pipeline)\n",
    "        'binary_classification_metrics': ['accuracy', 'roc_auc'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d7fa1",
   "metadata": {},
   "source": [
    "After implementing the fixed pipeline in a few lines of code, CaTabRa takes care of everything else: calculating descriptive statistics, splitting the data into training- and a test sets, training a classifier and an OOD detector, and evaluating the classifier on both training- and test set (including visualizations).\n",
    "\n",
    "The classifier can furthermore be explained without ado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "204e8c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Explanation started at 2023-03-08 14:39:12.430560\n",
      "[CaTabRa] *** Split train\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 570.05it/s]\n",
      "[CaTabRa] *** Split not_train\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 455.20it/s]\n",
      "[CaTabRa] ### Explanation finished at 2023-03-08 14:39:14.921295\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:02.490735\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/logreg_example/explain\n"
     ]
    }
   ],
   "source": [
    "from catabra.explanation import explain\n",
    "\n",
    "explain(\n",
    "    X,\n",
    "    folder='logreg_example',\n",
    "    from_invocation='logreg_example/invocation.json',\n",
    "    out='logreg_example/explain'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46aa022",
   "metadata": {},
   "source": [
    "## Configure Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975ce8b",
   "metadata": {},
   "source": [
    "Although fixed pipelines are, well, *fixed* in the sense that hyperparameters are not automatically optimized, it is still possible to configure hyperparameters through the config dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095284b",
   "metadata": {},
   "source": [
    "Find out which hyperparameters there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd46b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('minmaxscaler', MinMaxScaler()),\n",
       "  ('simpleimputer', SimpleImputer(fill_value=-1, strategy='constant')),\n",
       "  ('passthrough', 'passthrough')],\n",
       " 'verbose': False,\n",
       " 'minmaxscaler': MinMaxScaler(),\n",
       " 'simpleimputer': SimpleImputer(fill_value=-1, strategy='constant'),\n",
       " 'passthrough': 'passthrough',\n",
       " 'minmaxscaler__clip': False,\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'simpleimputer__add_indicator': False,\n",
       " 'simpleimputer__copy': True,\n",
       " 'simpleimputer__fill_value': -1,\n",
       " 'simpleimputer__missing_values': nan,\n",
       " 'simpleimputer__strategy': 'constant',\n",
       " 'simpleimputer__verbose': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e9a394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5c125",
   "metadata": {},
   "source": [
    "Hyperparameters can be configured by adding corresponding entries to the config dict. Keys must be prefixed by `\"logreg_preprocessing__\"` and `\"logreg_estimator__\"`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dcab7eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder \"/mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/logreg_example_configured\" already exists. Delete? [y/n] y\n",
      "[CaTabRa] ### Analysis started at 2023-03-08 15:00:22.444121\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend logreg for binary_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CaTabRa warning] Could not set number of jobs of Pipeline preprocessing to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 1\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type BinsDetector\n",
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-03-08 15:00:24.329333\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:01.885212\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/logreg_example_configured\n",
      "[CaTabRa] ### Evaluation started at 2023-03-08 15:00:24.334280\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    accuracy @ 0.5: 1.0\n",
      "    roc_auc: 1.0\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    accuracy @ 0.5: 0.9557522123893806\n",
      "    roc_auc: 0.9712643678160919\n",
      "[CaTabRa] ### Evaluation finished at 2023-03-08 15:00:28.631267\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:04.296987\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/logreg_example_configured/eval\n"
     ]
    }
   ],
   "source": [
    "analyze(\n",
    "    X,\n",
    "    classify='diagnosis',     # name of column containing classification target\n",
    "    split='train',            # name of column containing information about the train-test split (optional)\n",
    "    time=None,                # specifying a time budget has no effect on fixed pipelines\n",
    "    out='logreg_example_configured',\n",
    "    config={\n",
    "        'automl': 'logreg',   # name of the \"AutoML\" backend (in this case it's a fixed pipeline)\n",
    "        'binary_classification_metrics': ['accuracy', 'roc_auc'],\n",
    "        \n",
    "        'logreg_preprocessing__simpleimputer__strategy': 'mean',    # impute missing values with feature-wise mean\n",
    "        'logreg_estimator__penalty': 'none',                        # don't regularize\n",
    "        'logreg_estimator__max_iter': 500                           # increase number of iterations\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a92e3",
   "metadata": {},
   "source": [
    "## Bottom Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d4e27",
   "metadata": {},
   "source": [
    "Although it would be technically possible to incorporate hyperparameter optimization into fixed pipelines by utilizing `sklearn.model_selection.GridSearchCV` and related concepts, we **strongly recommend to implement a proper AutoML backend** instead. Refer to [AutoML-Extension.ipynb](https://github.com/risc-mi/catabra/tree/main/examples/AutoML-Extension.ipynb) for information how this works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

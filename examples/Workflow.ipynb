{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a749cba",
   "metadata": {},
   "source": [
    "# CaTabRa Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabba0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00087f16",
   "metadata": {},
   "source": [
    "This notebook is part of https://github.com/risc-mi/catabra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3641354",
   "metadata": {},
   "source": [
    "This tutorial demonstrates CaTabRa's main workflow, in particular how it can be used to\n",
    "* [analyze data with a binary target](#Step-1:-Analyze-Data-and-Train-Classifier),\n",
    "* [calibrate the classifier on dedicated calibration data](#Step-2:-Calibrate-Classifier),\n",
    "* [evaluate the classifier on held-out test data](#Step-3:-Evaluate-Classifier),\n",
    "* [explain the classifier by computing SHAP feature importance scores](#Step-4:-Explain-Classifier),\n",
    "* [apply the classifier to new data](#Step-5:-Apply-Classifier-to-New-Data), and\n",
    "* [load the classifier into Python](#Load-Classifier-into-Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3700ab",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5919d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic package imports\n",
    "from catabra.util import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de84497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory (where all generated artifacts, like statistics, models, etc. are saved)\n",
    "output_dir = 'workflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc686b7",
   "metadata": {},
   "source": [
    "## Step 0: Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a65b9",
   "metadata": {},
   "source": [
    "We are going to work with the [breast cancer](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) dataset, a well-known binary classification dataset.\n",
    "\n",
    "CaTabRa assumes a table in the usual $samples \\times attributes$ format as input, where the attributes encompass features, target labels, and possibly additional information like a predefined train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307d1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9029e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target labels to DataFrame\n",
    "X['diagnosis'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ef3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train- and test set by adding column with corresponding values\n",
    "# the name of the column is arbitrary; CaTabRa tries to \"guess\" which samples belong to which set based on the column name and -values\n",
    "X['train'] = X.index <= 0.8 * len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d800e752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst perimeter  worst area  worst smoothness  \\\n",
       "0                 0.07871  ...           184.60      2019.0            0.1622   \n",
       "1                 0.05667  ...           158.80      1956.0            0.1238   \n",
       "2                 0.05999  ...           152.50      1709.0            0.1444   \n",
       "3                 0.09744  ...            98.87       567.7            0.2098   \n",
       "4                 0.05883  ...           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  diagnosis  train  \n",
       "0                  0.11890          0   True  \n",
       "1                  0.08902          0   True  \n",
       "2                  0.08758          0   True  \n",
       "3                  0.17300          0   True  \n",
       "4                  0.07678          0   True  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f30be",
   "metadata": {},
   "source": [
    "**NOTE**<br>\n",
    "The column specifying the train-test split may contain more than two values. For instance, values `\"train\"`, `\"val\"` and `\"test\"` would yield a three-way split with one training set and two test sets. Only make sure that the column name and -values clearly indicate what the *training* set is meant to be; the names of the remaining sets are arbitrary. Prediction models are evaluated on each set (including the training set) separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b6a20",
   "metadata": {},
   "source": [
    "## Step 1: Analyze Data and Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be962c",
   "metadata": {},
   "source": [
    "Analyze the prepared data `X`. Only one simple function call is required to produce descriptive statistics, a high-quality classifier with automatically tuned hyperparameters, and an Out-of-Distribution detector.\n",
    "\n",
    "The corresponding command in CaTabRa's command-line interface is called `catabra analyze ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9f7b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Analysis started at 2023-02-02 11:02:08.734257\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend auto-sklearn for binary_classification\n",
      "[CaTabRa] Successfully loaded the following auto-sklearn add-on module(s): xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaletzk/miniconda3/envs/catabra/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/home/amaletzk/miniconda3/envs/catabra/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.980337\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:02\n",
      "[CaTabRa] New model #1 trained:\n",
      "    val_roc_auc: 0.980337\n",
      "    val_accuracy: 0.927152\n",
      "    val_balanced_accuracy: 0.928416\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:02\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:03\n",
      "[CaTabRa] New model #2 trained:\n",
      "    val_roc_auc: 0.994744\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.947717\n",
      "    train_roc_auc: 0.996970\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:03\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:04\n",
      "[CaTabRa] New model #3 trained:\n",
      "    val_roc_auc: 0.970098\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.915458\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:04\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:06\n",
      "[CaTabRa] New model #4 trained:\n",
      "    val_roc_auc: 0.975535\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.934034\n",
      "    train_roc_auc: 0.999866\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:06\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:08\n",
      "[CaTabRa] New model #5 trained:\n",
      "    val_roc_auc: 0.969192\n",
      "    val_accuracy: 0.913907\n",
      "    val_balanced_accuracy: 0.914734\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:08\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:09\n",
      "[CaTabRa] New model #6 trained:\n",
      "    val_roc_auc: 0.984143\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.934034\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:09\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994926\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New model #7 trained:\n",
      "    val_roc_auc: 0.980065\n",
      "    val_accuracy: 0.907285\n",
      "    val_balanced_accuracy: 0.914009\n",
      "    train_roc_auc: 0.995322\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.995832\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:16\n",
      "[CaTabRa] New model #8 trained:\n",
      "    val_roc_auc: 0.994201\n",
      "    val_accuracy: 0.973510\n",
      "    val_balanced_accuracy: 0.972635\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:16\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.995832\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:17\n",
      "[CaTabRa] New model #9 trained:\n",
      "    val_roc_auc: 0.978434\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.926694\n",
      "    train_roc_auc: 0.998574\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:17\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.995832\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:20\n",
      "[CaTabRa] New model #10 trained:\n",
      "    val_roc_auc: 0.985502\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.937206\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:19\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:20\n",
      "[CaTabRa] New model #11 trained:\n",
      "    val_roc_auc: 0.997282\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.927419\n",
      "    train_roc_auc: 0.995901\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:20\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New model #12 trained:\n",
      "    val_roc_auc: 0.976260\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.925245\n",
      "    train_roc_auc: 0.998886\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:26\n",
      "[CaTabRa] New model #13 trained:\n",
      "    val_roc_auc: 0.995107\n",
      "    val_accuracy: 0.973510\n",
      "    val_balanced_accuracy: 0.972635\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:26\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:28\n",
      "[CaTabRa] New model #14 trained:\n",
      "    val_roc_auc: 0.994020\n",
      "    val_accuracy: 0.953642\n",
      "    val_balanced_accuracy: 0.948441\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:27\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:29\n",
      "[CaTabRa] New model #15 trained:\n",
      "    val_roc_auc: 0.987858\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.942099\n",
      "    train_roc_auc: 1.000000\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:29\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:30\n",
      "[CaTabRa] New model #16 trained:\n",
      "    val_roc_auc: 0.994020\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.950163\n",
      "    train_roc_auc: 0.996569\n",
      "    type: sgd\n",
      "    total_elapsed_time: 00:30\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:31\n",
      "[CaTabRa] New model #17 trained:\n",
      "    val_roc_auc: 0.996557\n",
      "    val_accuracy: 0.966887\n",
      "    val_balanced_accuracy: 0.964570\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:31\n",
      "[CaTabRa] New model #18 trained:\n",
      "    val_roc_auc: 0.974175\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.920352\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:32\n",
      "[CaTabRa] New model #19 trained:\n",
      "    val_roc_auc: 0.981877\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.934034\n",
      "    train_roc_auc: 0.999955\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:34\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:35\n",
      "[CaTabRa] New model #20 trained:\n",
      "    val_roc_auc: 0.987767\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.956506\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:35\n",
      "[CaTabRa] New model #21 trained:\n",
      "    val_roc_auc: 0.876858\n",
      "    val_accuracy: 0.880795\n",
      "    val_balanced_accuracy: 0.876858\n",
      "    train_roc_auc: 1.000000\n",
      "    type: k_nearest_neighbors\n",
      "    total_elapsed_time: 00:36\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:37\n",
      "[CaTabRa] New model #22 trained:\n",
      "    val_roc_auc: 0.988039\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.956506\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:37\n",
      "[CaTabRa] New model #23 trained:\n",
      "    val_roc_auc: 0.982331\n",
      "    val_accuracy: 0.913907\n",
      "    val_balanced_accuracy: 0.914734\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:38\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:39\n",
      "[CaTabRa] New model #24 trained:\n",
      "    val_roc_auc: 0.990395\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.956506\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:39\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New model #25 trained:\n",
      "    val_roc_auc: 0.993838\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.941374\n",
      "    train_roc_auc: 0.997995\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:46\n",
      "[CaTabRa] New model #26 trained:\n",
      "    val_roc_auc: 0.993295\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.947717\n",
      "    train_roc_auc: 0.994386\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:46\n",
      "[CaTabRa] New model #27 trained:\n",
      "    val_roc_auc: 0.942008\n",
      "    val_accuracy: 0.741722\n",
      "    val_balanced_accuracy: 0.776006\n",
      "    train_roc_auc: 0.971039\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] New model #28 trained:\n",
      "    val_roc_auc: 0.965024\n",
      "    val_accuracy: 0.894040\n",
      "    val_balanced_accuracy: 0.897880\n",
      "    train_roc_auc: 0.988416\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:51\n",
      "[CaTabRa] New model #29 trained:\n",
      "    val_roc_auc: 0.860729\n",
      "    val_accuracy: 0.860927\n",
      "    val_balanced_accuracy: 0.845324\n",
      "    train_roc_auc: 0.987970\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:54\n",
      "[CaTabRa] New model #30 trained:\n",
      "    val_roc_auc: 0.979340\n",
      "    val_accuracy: 0.927152\n",
      "    val_balanced_accuracy: 0.930863\n",
      "    train_roc_auc: 0.999421\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:56\n",
      "[CaTabRa] New model #31 trained:\n",
      "    val_roc_auc: 0.838347\n",
      "    val_accuracy: 0.821192\n",
      "    val_balanced_accuracy: 0.831189\n",
      "    train_roc_auc: 1.000000\n",
      "    type: libsvm_svc\n",
      "    total_elapsed_time: 00:57\n",
      "[CaTabRa] New model #32 trained:\n",
      "    val_roc_auc: 0.969011\n",
      "    val_accuracy: 0.900662\n",
      "    val_balanced_accuracy: 0.893711\n",
      "    train_roc_auc: 0.973556\n",
      "    type: sgd\n",
      "    total_elapsed_time: 00:58\n",
      "[CaTabRa] New model #33 trained:\n",
      "    val_roc_auc: 0.944364\n",
      "    val_accuracy: 0.900662\n",
      "    val_balanced_accuracy: 0.898605\n",
      "    train_roc_auc: 0.968343\n",
      "    type: libsvm_svc\n",
      "    total_elapsed_time: 00:58\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 01:02\n",
      "[CaTabRa] New model #34 trained:\n",
      "    val_roc_auc: 0.992751\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.903226\n",
      "    train_roc_auc: 0.997861\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 01:02\n",
      "[CaTabRa] New model #35 trained:\n",
      "    val_roc_auc: 0.973904\n",
      "    val_accuracy: 0.900662\n",
      "    val_balanced_accuracy: 0.903498\n",
      "    train_roc_auc: 0.993896\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 01:03\n",
      "[CaTabRa] New model #36 trained:\n",
      "    val_roc_auc: 0.950797\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.913012\n",
      "    train_roc_auc: 1.000000\n",
      "    type: libsvm_svc\n",
      "    total_elapsed_time: 01:07\n",
      "[CaTabRa] New model #37 trained:\n",
      "    val_roc_auc: 0.906850\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.933212\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 01:07\n",
      "[CaTabRa] New model #38 trained:\n",
      "    val_roc_auc: 0.988945\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.937206\n",
      "    train_roc_auc: 0.993183\n",
      "    type: libsvm_svc\n",
      "    total_elapsed_time: 01:08\n",
      "[CaTabRa] New model #39 trained:\n",
      "    val_roc_auc: 0.757340\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.829932\n",
      "    type: mlp\n",
      "    total_elapsed_time: 01:12\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.997644\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 01:17\n",
      "[CaTabRa] New model #40 trained:\n",
      "    val_roc_auc: 0.992932\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.932584\n",
      "    train_roc_auc: 0.997639\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 01:16\n",
      "[CaTabRa] New model #41 trained:\n",
      "    val_roc_auc: 0.992932\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.942823\n",
      "    train_roc_auc: 0.994520\n",
      "    type: qda\n",
      "    total_elapsed_time: 01:17\n",
      "[CaTabRa] New model #42 trained:\n",
      "    val_roc_auc: 0.988764\n",
      "    val_accuracy: 0.927152\n",
      "    val_balanced_accuracy: 0.911290\n",
      "    train_roc_auc: 0.994787\n",
      "    type: lda\n",
      "    total_elapsed_time: 01:18\n",
      "[CaTabRa] New model #43 trained:\n",
      "    val_roc_auc: 0.984415\n",
      "    val_accuracy: 0.927152\n",
      "    val_balanced_accuracy: 0.911290\n",
      "    train_roc_auc: 0.993673\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 01:19\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.997282\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 01:20\n",
      "[CaTabRa] New model #44 trained:\n",
      "    val_roc_auc: 0.996738\n",
      "    val_accuracy: 0.973510\n",
      "    val_balanced_accuracy: 0.975082\n",
      "    train_roc_auc: 0.995901\n",
      "    type: qda\n",
      "    total_elapsed_time: 01:20\n",
      "[CaTabRa] New model #45 trained:\n",
      "    val_roc_auc: 0.934125\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 1.000000\n",
      "    type: libsvm_svc\n",
      "    total_elapsed_time: 01:21\n",
      "[CaTabRa] New model #46 trained:\n",
      "    val_roc_auc: 0.983690\n",
      "    val_accuracy: 0.900662\n",
      "    val_balanced_accuracy: 0.910837\n",
      "    train_roc_auc: 0.991980\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 01:25\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 01:28\n",
      "[CaTabRa] New model #47 trained:\n",
      "    val_roc_auc: 0.997644\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.927419\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:28\n",
      "[CaTabRa] New model #48 trained:\n",
      "    val_roc_auc: 0.964661\n",
      "    val_accuracy: 0.880795\n",
      "    val_balanced_accuracy: 0.857285\n",
      "    train_roc_auc: 0.969925\n",
      "    type: mlp\n",
      "    total_elapsed_time: 01:29\n",
      "[CaTabRa] New model #49 trained:\n",
      "    val_roc_auc: 0.939471\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.961014\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:30\n",
      "[CaTabRa] New model #50 trained:\n",
      "    val_roc_auc: 0.981153\n",
      "    val_accuracy: 0.655629\n",
      "    val_balanced_accuracy: 0.580645\n",
      "    train_roc_auc: 0.997906\n",
      "    type: qda\n",
      "    total_elapsed_time: 01:33\n",
      "[CaTabRa] New model #51 trained:\n",
      "    val_roc_auc: 0.982059\n",
      "    val_accuracy: 0.927152\n",
      "    val_balanced_accuracy: 0.928416\n",
      "    train_roc_auc: 0.999287\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 01:35\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 01:38\n",
      "[CaTabRa] New model #52 trained:\n",
      "    val_roc_auc: 0.994926\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.961399\n",
      "    train_roc_auc: 0.996614\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:38\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 01:43\n",
      "[CaTabRa] New model #53 trained:\n",
      "    val_roc_auc: 0.997100\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.954059\n",
      "    train_roc_auc: 0.996747\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:42\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998369\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 01:46\n",
      "[CaTabRa] New model #54 trained:\n",
      "    val_roc_auc: 0.997825\n",
      "    val_accuracy: 0.953642\n",
      "    val_balanced_accuracy: 0.945995\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:46\n",
      "[CaTabRa] New model #55 trained:\n",
      "    val_roc_auc: 0.867706\n",
      "    val_accuracy: 0.801325\n",
      "    val_balanced_accuracy: 0.758065\n",
      "    train_roc_auc: 1.000000\n",
      "    type: k_nearest_neighbors\n",
      "    total_elapsed_time: 01:47\n",
      "[CaTabRa] New model #56 trained:\n",
      "    val_roc_auc: 0.951794\n",
      "    val_accuracy: 0.596026\n",
      "    val_balanced_accuracy: 0.508065\n",
      "    train_roc_auc: 0.945019\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 01:48\n",
      "[CaTabRa] New model #57 trained:\n",
      "    val_roc_auc: 0.731968\n",
      "    val_accuracy: 0.741722\n",
      "    val_balanced_accuracy: 0.731968\n",
      "    train_roc_auc: 0.735007\n",
      "    type: decision_tree\n",
      "    total_elapsed_time: 01:52\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998188\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 01:56\n",
      "[CaTabRa] New model #58 trained:\n",
      "    val_roc_auc: 0.997644\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.927419\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:56\n",
      "[CaTabRa] New model #59 trained:\n",
      "    val_roc_auc: 0.992932\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.929141\n",
      "    train_roc_auc: 0.998129\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:00\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 02:05\n",
      "[CaTabRa] New model #60 trained:\n",
      "    val_roc_auc: 0.997463\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.927419\n",
      "    train_roc_auc: 0.996614\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:05\n",
      "[CaTabRa] New model #61 trained:\n",
      "    val_roc_auc: 0.994563\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.961399\n",
      "    train_roc_auc: 0.995945\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:09\n",
      "[CaTabRa] New model #62 trained:\n",
      "    val_roc_auc: 0.990758\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.942823\n",
      "    train_roc_auc: 0.998931\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] New model #63 trained:\n",
      "    val_roc_auc: 0.994744\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.942099\n",
      "    train_roc_auc: 0.996302\n",
      "    type: lda\n",
      "    total_elapsed_time: 02:13\n",
      "[CaTabRa] New model #64 trained:\n",
      "    val_roc_auc: 0.966564\n",
      "    val_accuracy: 0.907285\n",
      "    val_balanced_accuracy: 0.909116\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 02:14\n",
      "[CaTabRa] New model #65 trained:\n",
      "    val_roc_auc: 0.919627\n",
      "    val_accuracy: 0.867550\n",
      "    val_balanced_accuracy: 0.858282\n",
      "    train_roc_auc: 0.968678\n",
      "    type: gaussian_nb\n",
      "    total_elapsed_time: 02:18\n",
      "[CaTabRa] New model #66 trained:\n",
      "    val_roc_auc: 0.989670\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.942823\n",
      "    train_roc_auc: 0.998752\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:22\n",
      "[CaTabRa] New model #67 trained:\n",
      "    val_roc_auc: 0.471910\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.494475\n",
      "    type: bernoulli_nb\n",
      "    total_elapsed_time: 02:22\n",
      "[CaTabRa] New model #68 trained:\n",
      "    val_roc_auc: 0.906850\n",
      "    val_accuracy: 0.774834\n",
      "    val_balanced_accuracy: 0.791863\n",
      "    train_roc_auc: 0.948583\n",
      "    type: gaussian_nb\n",
      "    total_elapsed_time: 02:24\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 02:28\n",
      "[CaTabRa] New model #69 trained:\n",
      "    val_roc_auc: 0.997825\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.951613\n",
      "    train_roc_auc: 0.996614\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:28\n",
      "[CaTabRa] New model #70 trained:\n",
      "    val_roc_auc: 0.990758\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.926694\n",
      "    train_roc_auc: 0.997683\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:31\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 02:36\n",
      "[CaTabRa] New model #71 trained:\n",
      "    val_roc_auc: 0.997825\n",
      "    val_accuracy: 0.827815\n",
      "    val_balanced_accuracy: 0.790323\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:35\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 02:39\n",
      "[CaTabRa] New model #72 trained:\n",
      "    val_roc_auc: 0.997825\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:39\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 02:43\n",
      "[CaTabRa] New model #73 trained:\n",
      "    val_roc_auc: 0.997825\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:43\n",
      "[CaTabRa] New model #74 trained:\n",
      "    val_roc_auc: 0.500000\n",
      "    val_accuracy: 0.589404\n",
      "    val_balanced_accuracy: 0.500000\n",
      "    train_roc_auc: 0.500000\n",
      "    type: qda\n",
      "    total_elapsed_time: 02:44\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 7\n",
      "    total_elapsed_time: 02:48\n",
      "[CaTabRa] New model #75 trained:\n",
      "    val_roc_auc: 0.997825\n",
      "    val_accuracy: 0.834437\n",
      "    val_balanced_accuracy: 0.798387\n",
      "    train_roc_auc: 0.996569\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 02:48\n",
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 75\n",
      "    ensemble_val_roc_auc: 0.9980065241029358\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type Autoencoder\n",
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "Iteration 1, loss = 0.05672485\n",
      "Iteration 2, loss = 0.02719902\n",
      "Iteration 3, loss = 0.01696389\n",
      "Iteration 4, loss = 0.01381508\n",
      "Iteration 5, loss = 0.01272420\n",
      "Iteration 6, loss = 0.01219423\n",
      "Iteration 7, loss = 0.01208219\n",
      "Iteration 8, loss = 0.01193862\n",
      "Iteration 9, loss = 0.01171060\n",
      "Iteration 10, loss = 0.01149399\n",
      "Iteration 11, loss = 0.01133025\n",
      "Iteration 12, loss = 0.01149238\n",
      "Iteration 13, loss = 0.01132723\n",
      "Iteration 14, loss = 0.01131768\n",
      "Iteration 15, loss = 0.01096845\n",
      "Iteration 16, loss = 0.01240021\n",
      "Iteration 17, loss = 0.01292910\n",
      "Iteration 18, loss = 0.01180339\n",
      "Iteration 19, loss = 0.01142835\n",
      "Iteration 20, loss = 0.01145716\n",
      "Iteration 21, loss = 0.01143116\n",
      "Iteration 22, loss = 0.01098912\n",
      "Iteration 23, loss = 0.01077881\n",
      "Iteration 24, loss = 0.01032087\n",
      "Iteration 25, loss = 0.00920716\n",
      "Iteration 26, loss = 0.00799481\n",
      "Iteration 27, loss = 0.00767892\n",
      "Iteration 28, loss = 0.00725956\n",
      "Iteration 29, loss = 0.00644768\n",
      "Iteration 30, loss = 0.00612763\n",
      "Iteration 31, loss = 0.00571767\n",
      "Iteration 32, loss = 0.00549151\n",
      "Iteration 33, loss = 0.00547691\n",
      "Iteration 34, loss = 0.00537840\n",
      "Iteration 35, loss = 0.00533786\n",
      "Iteration 36, loss = 0.00568314\n",
      "Iteration 37, loss = 0.00585809\n",
      "Iteration 38, loss = 0.00623238\n",
      "Iteration 39, loss = 0.00555916\n",
      "Iteration 40, loss = 0.00552178\n",
      "Iteration 41, loss = 0.00538453\n",
      "Iteration 42, loss = 0.00531528\n",
      "Iteration 43, loss = 0.00531038\n",
      "Iteration 44, loss = 0.00527028\n",
      "Iteration 45, loss = 0.00525885\n",
      "Iteration 46, loss = 0.00524387\n",
      "Iteration 47, loss = 0.00525107\n",
      "Iteration 48, loss = 0.00522994\n",
      "Iteration 49, loss = 0.00522342\n",
      "Iteration 50, loss = 0.00521081\n",
      "Iteration 51, loss = 0.00519597\n",
      "Iteration 52, loss = 0.00519557\n",
      "Iteration 53, loss = 0.00519535\n",
      "Iteration 54, loss = 0.00518556\n",
      "Iteration 55, loss = 0.00518328\n",
      "Iteration 56, loss = 0.00517416\n",
      "Iteration 57, loss = 0.00516569\n",
      "Iteration 58, loss = 0.00516172\n",
      "Iteration 59, loss = 0.00515778\n",
      "Iteration 60, loss = 0.00515359\n",
      "Iteration 61, loss = 0.00514312\n",
      "Iteration 62, loss = 0.00514292\n",
      "Iteration 63, loss = 0.00514862\n",
      "Iteration 64, loss = 0.00513302\n",
      "Iteration 65, loss = 0.00516595\n",
      "Iteration 66, loss = 0.00516965\n",
      "Iteration 67, loss = 0.00514059\n",
      "Iteration 68, loss = 0.00514952\n",
      "Iteration 69, loss = 0.00513518\n",
      "Iteration 70, loss = 0.00515672\n",
      "Iteration 71, loss = 0.00517465\n",
      "Iteration 72, loss = 0.00517442\n",
      "Iteration 73, loss = 0.00516970\n",
      "Iteration 74, loss = 0.00517367\n",
      "Iteration 75, loss = 0.00515799\n",
      "Iteration 76, loss = 0.00514898\n",
      "Iteration 77, loss = 0.00512780\n",
      "Iteration 78, loss = 0.00513351\n",
      "Iteration 79, loss = 0.00511325\n",
      "Iteration 80, loss = 0.00511835\n",
      "Iteration 81, loss = 0.00511637\n",
      "Iteration 82, loss = 0.00510972\n",
      "Iteration 83, loss = 0.00512365\n",
      "Training loss did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-02-02 11:05:12.042835\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:03:03.308578\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification\n",
      "[CaTabRa] ### Evaluation started at 2023-02-02 11:05:12.090531\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    roc_auc: 0.9971923536439665\n",
      "    accuracy @ 0.5: 0.9517543859649122\n",
      "    balanced_accuracy @ 0.5: 0.9416965352449224\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    roc_auc: 0.9973474801061007\n",
      "    accuracy @ 0.5: 0.9734513274336283\n",
      "    balanced_accuracy @ 0.5: 0.95579133510168\n",
      "[CaTabRa] ### Evaluation finished at 2023-02-02 11:05:17.399389\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:05.308858\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/eval\n"
     ]
    }
   ],
   "source": [
    "from catabra.analysis import analyze\n",
    "\n",
    "analyze(\n",
    "    X,                        # table to analyze; can also be the path to a CSV/Excel/HDF5 file\n",
    "    classify='diagnosis',     # name of column containing classification target\n",
    "    split='train',            # name of column containing information about the train-test split (optional)\n",
    "    time=3,                   # time budget for hyperparameter tuning, in minutes (optional)\n",
    "    out=output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa214ee",
   "metadata": {},
   "source": [
    "By specifying a train-test split, CaTabRa not only trains a classifier (on the training set) but also evaluates it (on both sets). The last few lines of the above logging output inform about the performance of the classifier on \"train\" and \"not_train\". More detailed results are available as well, as we will see in [Step 3](#Step-3:-Evaluate-Classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa54b34",
   "metadata": {},
   "source": [
    "The newly created directory specified by `output_dir` contains all results generated during data analysis, including\n",
    "* a copy of the used configuration: `config.json`,\n",
    "* the arguments passed to function `analyze()`: `invocation.json`,\n",
    "* [descriptive statistics of the analyzed data](#Descriptive-Statistics): `statistics/`,\n",
    "* the trained prediction model: `model.joblib`,\n",
    "* [information about the constituents of the prediction model and their hyperparameters](#Model-Summary): `model_summary.json`,\n",
    "* [the training history](#Training-History): `training_history.xlsx` and `training_history.pdf`,\n",
    "* the OOD-detector: `ood.joblib`, and\n",
    "* evaluation results (because we specified a train-test split): `eval/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899d48b",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8511f",
   "metadata": {},
   "source": [
    "Descriptive statistics are calculated for numeric and non-numeric (categorical) features separately and saved in `statistics/statistics_numeric.xlsx` and `statistics/statistics/non_numeric.xlsx`. It is easiest to simply view these files in Excel, but they can of course be loaded as pandas DataFrames, too.\n",
    "\n",
    "CaTabRa provides a convience function for loading tables in arbitrary format, implemented in module `catabra.util.io`: `read_df()` for loading a single table and `read_dfs()` for loading all tables stored in a file. In classification tasks, descriptive statistics are computed both for the entire dataset and for each class individually and written to two different tables, so we use `read_dfs()` to load both of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e6da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = io.read_dfs(output_dir + '/statistics/statistics_numeric.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d596b978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>569</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.98100</td>\n",
       "      <td>11.70000</td>\n",
       "      <td>13.37000</td>\n",
       "      <td>15.7800</td>\n",
       "      <td>28.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>569</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.71000</td>\n",
       "      <td>16.17000</td>\n",
       "      <td>18.84000</td>\n",
       "      <td>21.8000</td>\n",
       "      <td>39.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>569</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.79000</td>\n",
       "      <td>75.17000</td>\n",
       "      <td>86.24000</td>\n",
       "      <td>104.1000</td>\n",
       "      <td>188.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean area</td>\n",
       "      <td>569</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.50000</td>\n",
       "      <td>420.30000</td>\n",
       "      <td>551.10000</td>\n",
       "      <td>782.7000</td>\n",
       "      <td>2501.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean smoothness</td>\n",
       "      <td>569</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.09587</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.1634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  count        mean         std        min        25%  \\\n",
       "0      mean radius    569   14.127292    3.524049    6.98100   11.70000   \n",
       "1     mean texture    569   19.289649    4.301036    9.71000   16.17000   \n",
       "2   mean perimeter    569   91.969033   24.298981   43.79000   75.17000   \n",
       "3        mean area    569  654.889104  351.914129  143.50000  420.30000   \n",
       "4  mean smoothness    569    0.096360    0.014064    0.05263    0.08637   \n",
       "\n",
       "         50%       75%        max  \n",
       "0   13.37000   15.7800    28.1100  \n",
       "1   18.84000   21.8000    39.2800  \n",
       "2   86.24000  104.1000   188.5000  \n",
       "3  551.10000  782.7000  2501.0000  \n",
       "4    0.09587    0.1053     0.1634  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall statistics\n",
    "stats['overall'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dd1a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>mann_whitney_u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>17.462830</td>\n",
       "      <td>3.203971</td>\n",
       "      <td>10.950</td>\n",
       "      <td>15.0750</td>\n",
       "      <td>17.325</td>\n",
       "      <td>19.590</td>\n",
       "      <td>28.11</td>\n",
       "      <td>2.692943e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean radius</td>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>12.146524</td>\n",
       "      <td>1.780512</td>\n",
       "      <td>6.981</td>\n",
       "      <td>11.0800</td>\n",
       "      <td>12.200</td>\n",
       "      <td>13.370</td>\n",
       "      <td>17.85</td>\n",
       "      <td>2.692943e-68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>3.779470</td>\n",
       "      <td>10.380</td>\n",
       "      <td>19.3275</td>\n",
       "      <td>21.460</td>\n",
       "      <td>23.765</td>\n",
       "      <td>39.28</td>\n",
       "      <td>3.428627e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean texture</td>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>3.995125</td>\n",
       "      <td>9.710</td>\n",
       "      <td>15.1500</td>\n",
       "      <td>17.390</td>\n",
       "      <td>19.760</td>\n",
       "      <td>33.81</td>\n",
       "      <td>3.428627e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean perimeter</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>115.365377</td>\n",
       "      <td>21.854653</td>\n",
       "      <td>71.900</td>\n",
       "      <td>98.7450</td>\n",
       "      <td>114.200</td>\n",
       "      <td>129.925</td>\n",
       "      <td>188.50</td>\n",
       "      <td>3.553870e-71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  diagnosis  count        mean        std     min      25%  \\\n",
       "0     mean radius          0    212   17.462830   3.203971  10.950  15.0750   \n",
       "1     mean radius          1    357   12.146524   1.780512   6.981  11.0800   \n",
       "2    mean texture          0    212   21.604906   3.779470  10.380  19.3275   \n",
       "3    mean texture          1    357   17.914762   3.995125   9.710  15.1500   \n",
       "4  mean perimeter          0    212  115.365377  21.854653  71.900  98.7450   \n",
       "\n",
       "       50%      75%     max  mann_whitney_u  \n",
       "0   17.325   19.590   28.11    2.692943e-68  \n",
       "1   12.200   13.370   17.85    2.692943e-68  \n",
       "2   21.460   23.765   39.28    3.428627e-28  \n",
       "3   17.390   19.760   33.81    3.428627e-28  \n",
       "4  114.200  129.925  188.50    3.553870e-71  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics per class\n",
    "stats['diagnosis']['Feature'].fillna(method='ffill', inplace=True)\n",
    "stats['diagnosis'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee152a5f",
   "metadata": {},
   "source": [
    "In the above per-class statistics, a [Mann-Whitney *U* test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) is performed to detect statistically significant differences in the distribution of a feature between the different classes, and the resulting *p*-values are reported in column `mann_whitney_u`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a2f16",
   "metadata": {},
   "source": [
    "For more information about the descriptive statistics computed by CaTabRa by default, refer to `/doc/statistics.md`.\n",
    "\n",
    "Descriptive statistics can be computed manually as well, see module `catabra.util.statistics` for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1db4ed",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8266b2",
   "metadata": {},
   "source": [
    "The final prediction model is summarized in `model_summary.json`. This file contains a dict with information about the individual constituent models (if the model is an ensemble), the used preprocessing steps, and the selected hyperparameter values. The exact format depends on the used AutoML backend, but for the default auto-sklearn backend the main information is contained in the list under the `\"models\"` key, as can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fb2210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'automl': 'auto-sklearn',\n",
       " 'task': 'binary_classification',\n",
       " 'models': [{'model_id': 55,\n",
       "   'rank': 1,\n",
       "   'cost': 0.002174700978615496,\n",
       "   'ensemble_weight': 0.2,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'most_frequent' rescaling:__choice__, Value: 'robust_scaler' rescaling:robust_scaler:q_max, Value: 0.880381628929301 rescaling:robust_scaler:q_min, Value: 0.1341131843923... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': \"Balancing(random_state=1, strategy='weighting')\",\n",
       "   'feature_preprocessor': \"FastICA(algorithm='parallel', fun='exp', n_components=314, random_state=1, whiten=True)\",\n",
       "   'classifier': \"LinearSVC(C=0.6406426017332504, class_weight='balanced', dual=False, intercept_scaling=1.0, random_state=1, tol=0.00012928412068849977)\"},\n",
       "  {'model_id': 70,\n",
       "   'rank': 2,\n",
       "   'cost': 0.002174700978615496,\n",
       "   'ensemble_weight': 0.1,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'mean' rescaling:__choice__, Value: 'standardize' , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Numer... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': \"Balancing(random_state=1, strategy='weighting')\",\n",
       "   'feature_preprocessor': \"FastICA(algorithm='deflation', fun='logcosh', n_components=134, random_state=1, whiten=True)\",\n",
       "   'classifier': \"LinearSVC(C=0.037102666451776, class_weight='balanced', dual=False, intercept_scaling=1.0, random_state=1, tol=7.012538595303216e-05)\"},\n",
       "  {'model_id': 74,\n",
       "   'rank': 3,\n",
       "   'cost': 0.002174700978615496,\n",
       "   'ensemble_weight': 0.1,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'most_frequent' rescaling:__choice__, Value: 'robust_scaler' rescaling:robust_scaler:q_max, Value: 0.9527018660917124 rescaling:robust_scaler:q_min, Value: 0.244393139319... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': 'Balancing(random_state=1)',\n",
       "   'feature_preprocessor': \"FastICA(algorithm='parallel', fun='exp', n_components=1324, random_state=1, whiten=True)\",\n",
       "   'classifier': 'LinearSVC(C=0.03694688108813779, dual=False, intercept_scaling=1.0, random_state=1, tol=3.5388917975900854e-05)'},\n",
       "  {'model_id': 76,\n",
       "   'rank': 4,\n",
       "   'cost': 0.002174700978615496,\n",
       "   'ensemble_weight': 0.2,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'mean' rescaling:__choice__, Value: 'standardize' , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Numer... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': 'Balancing(random_state=1)',\n",
       "   'feature_preprocessor': \"FastICA(algorithm='deflation', fun='logcosh', n_components=216, random_state=1, whiten=True)\",\n",
       "   'classifier': 'LinearSVC(C=0.18298402049436568, dual=False, intercept_scaling=1.0, random_state=1, tol=2.0508587358230552e-05)'},\n",
       "  {'model_id': 48,\n",
       "   'rank': 5,\n",
       "   'cost': 0.0023559260601667686,\n",
       "   'ensemble_weight': 0.1,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'mean' rescaling:__choice__, Value: 'standardize' , dataset_properties={'signed': False, 'sparse': False}, exclude={}, include={}, init_params={}, steps=[('imputation', Numer... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': 'Balancing(random_state=1)',\n",
       "   'feature_preprocessor': \"FastICA(algorithm='deflation', fun='exp', n_components=104, random_state=1, whiten=True)\",\n",
       "   'classifier': 'LinearSVC(C=1.6256122240448774, dual=False, intercept_scaling=1.0, random_state=1, tol=5.7569680509488696e-05)'},\n",
       "  {'model_id': 59,\n",
       "   'rank': 6,\n",
       "   'cost': 0.0023559260601667686,\n",
       "   'ensemble_weight': 0.2,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'median' rescaling:__choice__, Value: 'robust_scaler' rescaling:robust_scaler:q_max, Value: 0.75 rescaling:robust_scaler:q_min, Value: 0.26413154772675485 , dataset_propert... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': 'Balancing(random_state=1)',\n",
       "   'feature_preprocessor': \"FastICA(algorithm='deflation', fun='exp', n_components=216, random_state=1, whiten=True)\",\n",
       "   'classifier': 'LinearSVC(C=1.6256122240448774, dual=False, intercept_scaling=1.0, random_state=1, tol=1.0628097125906722e-05)'},\n",
       "  {'model_id': 12,\n",
       "   'rank': 7,\n",
       "   'cost': 0.0027183762232693143,\n",
       "   'ensemble_weight': 0.1,\n",
       "   'data_preprocessor': \"FeatTypeSplit(column_transformer=ColumnTransformer(sparse_threshold=0.0, transformers=[('numerical_transformer', NumericalPreprocessingPipeline(config=Configuration: imputation:strategy, Value: 'most_frequent' rescaling:__choice__, Value: 'robust_scaler' rescaling:robust_scaler:q_max, Value: 0.7278293151795671 rescaling:robust_scaler:q_min, Value: 0.162718521227... 'symmetry error': 'numerical', 'texture error': 'numerical', 'worst area': 'numerical', 'worst compactness': 'numerical', 'worst concave points': 'numerical', 'worst concavity': 'numerical', 'worst fractal dimension': 'numerical', 'worst perimeter': 'numerical', 'worst radius': 'numerical', 'worst smoothness': 'numerical', 'worst symmetry': 'numerical', 'worst texture': 'numerical'}, init_params={})\",\n",
       "   'balancing': \"Balancing(random_state=1, strategy='weighting')\",\n",
       "   'feature_preprocessor': \"FastICA(algorithm='deflation', fun='exp', n_components=1631, random_state=1, whiten=True)\",\n",
       "   'classifier': 'PassiveAggressiveClassifier(C=0.008807665845919431, max_iter=128, random_state=1, tol=0.001174447028725537, warm_start=True)'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.load(output_dir + '/model_summary.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abb251",
   "metadata": {},
   "source": [
    "### Training History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1450f",
   "metadata": {},
   "source": [
    "Information about each model trained during hyperparameter optimization is contained in `training_history.xlsx` and visualized in `training_history.pdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44407657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>total_elapsed_time</th>\n",
       "      <th>type</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_balanced_accuracy</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>ensemble_weight</th>\n",
       "      <th>ensemble_val_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-02 11:02:12.170</td>\n",
       "      <td>0 days 00:00:02.362576485</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.980337</td>\n",
       "      <td>0.927152</td>\n",
       "      <td>0.928416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.134844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-02-02 11:02:12.896</td>\n",
       "      <td>0 days 00:00:03.087956190</td>\n",
       "      <td>passive_aggressive</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.947020</td>\n",
       "      <td>0.947717</td>\n",
       "      <td>0.996970</td>\n",
       "      <td>0.609202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-02 11:02:13.851</td>\n",
       "      <td>0 days 00:00:04.043154955</td>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0.970098</td>\n",
       "      <td>0.920530</td>\n",
       "      <td>0.915458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-02-02 11:02:15.418</td>\n",
       "      <td>0 days 00:00:05.609847546</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.975535</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.934034</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>1.421740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2023-02-02 11:02:17.481</td>\n",
       "      <td>0 days 00:00:07.673421621</td>\n",
       "      <td>mlp</td>\n",
       "      <td>0.969192</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.914734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.909986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id               timestamp         total_elapsed_time  \\\n",
       "0         2 2023-02-02 11:02:12.170  0 days 00:00:02.362576485   \n",
       "1         3 2023-02-02 11:02:12.896  0 days 00:00:03.087956190   \n",
       "2         4 2023-02-02 11:02:13.851  0 days 00:00:04.043154955   \n",
       "3         5 2023-02-02 11:02:15.418  0 days 00:00:05.609847546   \n",
       "4         6 2023-02-02 11:02:17.481  0 days 00:00:07.673421621   \n",
       "\n",
       "                 type  val_roc_auc  val_accuracy  val_balanced_accuracy  \\\n",
       "0       random_forest     0.980337      0.927152               0.928416   \n",
       "1  passive_aggressive     0.994744      0.947020               0.947717   \n",
       "2   gradient_boosting     0.970098      0.920530               0.915458   \n",
       "3       random_forest     0.975535      0.933775               0.934034   \n",
       "4                 mlp     0.969192      0.913907               0.914734   \n",
       "\n",
       "   train_roc_auc  duration  ensemble_weight  ensemble_val_roc_auc  \n",
       "0       1.000000  1.134844              0.0              0.980337  \n",
       "1       0.996970  0.609202              0.0              0.994744  \n",
       "2       1.000000  0.818402              0.0              0.994744  \n",
       "3       0.999866  1.421740              0.0              0.994744  \n",
       "4       1.000000  1.909986              0.0              0.994744  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.read_df(output_dir + '/training_history.xlsx').drop('Unnamed: 0', axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40797561",
   "metadata": {},
   "source": [
    "## Step 2: Calibrate Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c1df53",
   "metadata": {},
   "source": [
    "Classifiers can be calibrated to ensure that the probability estimates they return correspond to the \"true\" confidence of the model. As in the initial data analysis and model construction, one simple function call suffices to calibrate a classifier in CaTabRa.\n",
    "\n",
    "Worth noting are the use of the `from_invocation` keyword argument, which automatically sets all unspecified arguments to the values stored in the given JSON file; this, for example, applies to `split`. The effect of setting `subset` to `True` is that the classifier is only calibrated on those samples whose value in the train-test-split column `\"train\"` is `True` (i.e., the training set). Normally, classifiers should not be calibrated on the training set, though. After calibration, `model.joblib` is replaced by the new, calibrated model.\n",
    "\n",
    "The corresponding command in CaTabRa's command-line interface is `catabra calibrate ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "762b284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Calibration started at 2023-02-02 14:11:34.968525\n",
      "[CaTabRa] Restricting table to calibration subset train = True (456 entries)\n",
      "[CaTabRa] ### Calibration finished at 2023-02-02 14:11:36.697882\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:01.729357\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/calib\n"
     ]
    }
   ],
   "source": [
    "from catabra.calibration import calibrate\n",
    "\n",
    "calibrate(\n",
    "    X,\n",
    "    folder=output_dir,    # directory containing trained classifier (= output directory of previous call to `analyze()`)\n",
    "    from_invocation=output_dir + '/invocation.json',\n",
    "    subset=True,\n",
    "    out=output_dir + '/calib'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841fbcb",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e51ac",
   "metadata": {},
   "source": [
    "Prediction models can be evaluated on (labeled) data that have the same format as the data they were initially trained on, as passed to function `analyze()`. Again, one simple function call is sufficient. If the data is split into two or more disjoint subsets via argument `split` (implicit in `from_invocation` below), the model is evaluated on each of these subsets separately.\n",
    "\n",
    "[Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) can be used to obtain estimates on the variance, confidence interval, etc. of the performance of our classifier. We activate it by simply setting `bootstrapping_repetitions` to the desired number of repetitions.\n",
    "\n",
    "Since the desired output directory has been created by function `analyze()` already, we are asked whether it should be replaced.\n",
    "\n",
    "The corresponding command in CaTabRa's command-line interface is `catabra evaluate ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75b90218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation folder \"/mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/eval\" already exists. Delete? [y/n] y\n",
      "[CaTabRa] ### Evaluation started at 2023-02-02 16:14:11.106915\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    roc_auc: 0.9971923536439665\n",
      "    accuracy @ 0.5: 0.9736842105263158\n",
      "    balanced_accuracy @ 0.5: 0.9702508960573477\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    roc_auc: 0.9973474801061007\n",
      "    accuracy @ 0.5: 0.9734513274336283\n",
      "    balanced_accuracy @ 0.5: 0.9692749778956675\n",
      "[CaTabRa] ### Evaluation finished at 2023-02-02 16:14:27.249299\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:16.142384\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/eval\n"
     ]
    }
   ],
   "source": [
    "from catabra.evaluation import evaluate\n",
    "\n",
    "evaluate(\n",
    "    X,\n",
    "    folder=output_dir,    # directory containing trained classifier (= output directory of previous call to `analyze()`)\n",
    "    from_invocation=output_dir + '/invocation.json',\n",
    "    bootstrapping_repetitions=1000,   # number of bootstrapping repetitions to perform; set to 0 to disable bootstrapping\n",
    "    out=output_dir + '/eval'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6539bcc",
   "metadata": {},
   "source": [
    "Note how accuracy and balanced accuracy changed compared to the initial data analysis. This is because of model calibration, which potentially affects thresholded metrics (like accuracy and balanced accuracy) but leaves threshold-independent metrics, like ROC-AUC, unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e960f",
   "metadata": {},
   "source": [
    "### Performance Metrics (Non-Bootstrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf23ce9",
   "metadata": {},
   "source": [
    "One of the main evaluation results produced by CaTabRa are tables with detailed information on model performance, and corresponding visualizations. In our case, they are contained in subdirectories `eval/train/` and `eval/not_train/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20414c3",
   "metadata": {},
   "source": [
    "Non-bootstrapped performance metrics are saved in `metrics.xlsx`. In binary classification, this file consists of the three tables `\"overall\"`, `\"thresholded\"` and `\"calibration\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666f102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = io.read_dfs(output_dir + '/eval/not_train/metrics.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0172186",
   "metadata": {},
   "source": [
    "Table `\"overall\"` contains non-thresholded performance metrics, like ROC-AUC, average precision, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5ac2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pos_label</th>\n",
       "      <th>n</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>brier_loss</th>\n",
       "      <th>hinge_loss</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>87</td>\n",
       "      <td>0.997347</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.293878</td>\n",
       "      <td>0.086603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  pos_label    n  n_pos   roc_auc  average_precision    pr_auc  \\\n",
       "0  diagnosis          1  113     87  0.997347           0.999216  0.999211   \n",
       "\n",
       "   brier_loss  hinge_loss  log_loss  \n",
       "0    0.023292    0.293878  0.086603  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26061c2",
   "metadata": {},
   "source": [
    "Table `\"thresholded\"` contains all performance metrics that depend on a specific decision threshold (a.k.a. cut-off point), like accuracy, balanced accuracy, F1-score, etc. These metrics are evaluated at different decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b707893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>positive_predictive_value</th>\n",
       "      <th>negative_predictive_value</th>\n",
       "      <th>cohen_kappa</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>true_positive</th>\n",
       "      <th>true_negative</th>\n",
       "      <th>false_positive</th>\n",
       "      <th>false_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.159968e-08</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230088</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.942590e-06</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.656417e-06</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.222603e-06</td>\n",
       "      <td>0.796460</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.883249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167254</td>\n",
       "      <td>0.203540</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.910255e-05</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268270</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>87</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      threshold  accuracy  balanced_accuracy        f1  sensitivity  \\\n",
       "0  5.159968e-08  0.769912           0.500000  0.870000          1.0   \n",
       "1  1.942590e-06  0.778761           0.519231  0.874372          1.0   \n",
       "2  2.656417e-06  0.787611           0.538462  0.878788          1.0   \n",
       "3  8.222603e-06  0.796460           0.557692  0.883249          1.0   \n",
       "4  2.910255e-05  0.814159           0.596154  0.892308          1.0   \n",
       "\n",
       "   specificity  positive_predictive_value  negative_predictive_value  \\\n",
       "0     0.000000                   0.769912                        1.0   \n",
       "1     0.038462                   0.776786                        1.0   \n",
       "2     0.076923                   0.783784                        1.0   \n",
       "3     0.115385                   0.790909                        1.0   \n",
       "4     0.192308                   0.805556                        1.0   \n",
       "\n",
       "   cohen_kappa  hamming_loss   jaccard  true_positive  true_negative  \\\n",
       "0     0.000000      0.230088  0.769912             87              0   \n",
       "1     0.058019      0.221239  0.776786             87              1   \n",
       "2     0.113725      0.212389  0.783784             87              2   \n",
       "3     0.167254      0.203540  0.790909             87              3   \n",
       "4     0.268270      0.185841  0.805556             87              5   \n",
       "\n",
       "   false_positive  false_negative  \n",
       "0              26               0  \n",
       "1              25               0  \n",
       "2              24               0  \n",
       "3              23               0  \n",
       "4              21               0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['thresholded'].drop('Unnamed: 0', axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287e63c",
   "metadata": {},
   "source": [
    "Table `\"calibration\"` contains the fraction of positive samples for different threshold intervals. The intervals are constructed such that each of them contains roughly the same number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "603c0b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold_lower</th>\n",
       "      <th>threshold_upper</th>\n",
       "      <th>pos_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.159968e-08</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.222603e-06</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.207743e-05</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.075891e-04</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.485546e-04</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold_lower  threshold_upper  pos_fraction\n",
       "0     5.159968e-08         0.000008           0.0\n",
       "1     8.222603e-06         0.000032           0.0\n",
       "2     3.207743e-05         0.000108           0.0\n",
       "3     1.075891e-04         0.000149           0.0\n",
       "4     1.485546e-04         0.000790           0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['calibration'].drop('Unnamed: 0', axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397afbda",
   "metadata": {},
   "source": [
    "### Bootstrapped Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516cfa8",
   "metadata": {},
   "source": [
    "Since we activated bootstrapping by setting `bootstrapping_repetitions` to a positive number, file `bootstrapping.xlsx` was generated. It contains two tables `\"summary\"` and `\"details\"` with summary statistics over all bootstrapping runs and the runs themselves, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3e62bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapping = io.read_dfs(output_dir + '/eval/not_train/bootstrapping.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a9697e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>__threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>0.973504</td>\n",
       "      <td>0.969157</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.958152</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.971778</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0      roc_auc     accuracy  balanced_accuracy  __threshold\n",
       "0      count  1000.000000  1000.000000        1000.000000       1000.0\n",
       "1       mean     0.997224     0.973504           0.969157          0.5\n",
       "2        std     0.002679     0.014629           0.020406          0.0\n",
       "3        min     0.982759     0.920354           0.890215          0.5\n",
       "4        25%     0.996055     0.964602           0.958152          0.5\n",
       "5        50%     0.997841     0.973451           0.971778          0.5\n",
       "6        75%     0.999160     0.982301           0.983516          0.5\n",
       "7        max     1.000000     1.000000           1.000000          0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrapping['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f72544",
   "metadata": {},
   "source": [
    "Table `\"details\"` reports the performance metrics for each single run, together with the random seed used for resampling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5464a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>__seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998864</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.978598</td>\n",
       "      <td>3937181777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998739</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>3822484485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997537</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.970238</td>\n",
       "      <td>192133578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999139</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.975668</td>\n",
       "      <td>3230327960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>1867172167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roc_auc  accuracy  balanced_accuracy      __seed\n",
       "0  0.998864  0.982301           0.978598  3937181777\n",
       "1  0.998739  0.964602           0.976471  3822484485\n",
       "2  0.997537  0.955752           0.970238   192133578\n",
       "3  0.999139  0.982301           0.975668  3230327960\n",
       "4  0.999482  0.991150           0.994565  1867172167"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrapping['details'].drop('Unnamed: 0', axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202515e",
   "metadata": {},
   "source": [
    "### Sample-Wise Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808c1f7",
   "metadata": {},
   "source": [
    "Finally, the model output for each individual sample is saved in `predictions.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f61eb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = io.read_df(output_dir + '/eval/not_train/predictions.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7519cf0",
   "metadata": {},
   "source": [
    "The table contains the true label (column `\"diagnosis\"`) and the predicted probabilities of the negative and positive class, respectively. Note that in our cases the two classes are simply called `0` and `1`, which is why the corresponding columns are called `\"0_proba\"` and `\"1_proba\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67ec9d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>0_proba</th>\n",
       "      <th>1_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.837965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034214</td>\n",
       "      <td>0.965786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017535</td>\n",
       "      <td>0.982465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.999421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  diagnosis   0_proba   1_proba\n",
       "0         456          1  0.162035  0.837965\n",
       "1         457          1  0.034214  0.965786\n",
       "2         458          1  0.017535  0.982465\n",
       "3         459          1  0.000579  0.999421\n",
       "4         460          0  0.999971  0.000029"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a5302",
   "metadata": {},
   "source": [
    "## Step 4: Explain Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ea5dc",
   "metadata": {},
   "source": [
    "Prediction models can be explained on data that have the same format as the data they were initially trained on, as passed to function `analyze()`. As before, one simple function call is sufficient. If the data is split into two or more disjoint subsets via argument `split` (implicit in `from_invocation` below), the model is explained on each of these subsets separately.\n",
    "\n",
    "If the final model is an ensemble of several base models, each of them is expained separately.\n",
    "\n",
    "The corresponding command in CaTabRa's command-line interface is `catabra explain ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "100da7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation folder \"/mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/explain\" already exists. Delete? [y/n] y\n",
      "[CaTabRa] ### Explanation started at 2023-02-03 15:23:47.444648\n",
      "[CaTabRa] *** Split train\n",
      "Model 55 (1 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 542.90it/s]\n",
      "Model 70 (2 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 639.03it/s]\n",
      "Model 74 (3 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 663.65it/s]\n",
      "Model 76 (4 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 670.85it/s]\n",
      "Model 48 (5 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 621.31it/s]\n",
      "Model 59 (6 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 540.28it/s]\n",
      "Model 12 (7 of 7):\n",
      "Sample batches: 100%|########################################| 15/15 [00:00<00:00, 632.18it/s]\n",
      "[CaTabRa] *** Split not_train\n",
      "Model 55 (1 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 309.63it/s]\n",
      "Model 70 (2 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 384.22it/s]\n",
      "Model 74 (3 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 303.84it/s]\n",
      "Model 76 (4 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 298.66it/s]\n",
      "Model 48 (5 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 304.65it/s]\n",
      "Model 59 (6 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 311.16it/s]\n",
      "Model 12 (7 of 7):\n",
      "Sample batches: 100%|########################################| 4/4 [00:00<00:00, 295.26it/s]\n",
      "[CaTabRa] ### Explanation finished at 2023-02-03 15:24:05.589268\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:18.144620\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/explain\n"
     ]
    }
   ],
   "source": [
    "from catabra.explanation import explain\n",
    "\n",
    "explain(\n",
    "    X,\n",
    "    folder=output_dir,    # directory containing trained classifier (= output directory of previous call to `analyze()`)\n",
    "    from_invocation=output_dir + '/invocation.json',\n",
    "    out=output_dir + '/explain'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f4218",
   "metadata": {},
   "source": [
    "The resulting SHAP feature importance scores are saved as HDF5 tables and visualized in so-called *beeswarm* plots, and can be found in the specified output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a03c4",
   "metadata": {},
   "source": [
    "## Step 5: Apply Classifier to New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01545bac",
   "metadata": {},
   "source": [
    "Finally, the trained classifier can be applied to new data of the same format as the data it was initially trained on, possibly without the label column. For demonstration purposes we apply the classifier to the same data `X` we are using throughout, although in a real-world use-case this would not make sense.\n",
    "\n",
    "The corresponding command in CaTabRa's command-line interface is `catabra apply ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3698d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application folder \"/mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/apply\" already exists. Delete? [y/n] y\n",
      "[CaTabRa] ### Application started at 2023-02-03 15:40:10.451366\n",
      "[CaTabRa] ### Application finished at 2023-02-03 15:40:12.484966\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:02.033600\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/apply\n"
     ]
    }
   ],
   "source": [
    "from catabra.application import apply\n",
    "\n",
    "apply(\n",
    "    X.drop('diagnosis', axis=1),   # data to apply the model to; column containing ground-truth labels is not needed (but would not harm either)\n",
    "    folder=output_dir,    # directory containing trained classifier (= output directory of previous call to `analyze()`)\n",
    "    from_invocation=output_dir + '/invocation.json',\n",
    "    out=output_dir + '/apply'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef23b44",
   "metadata": {},
   "source": [
    "The results are saved in `predictions.xlsx` and contain the predicted probabilities of the two classes, for every sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1b6efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = io.read_df(output_dir + '/apply/predictions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ac15042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0_proba</th>\n",
       "      <th>1_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.998161</td>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   0_proba   1_proba\n",
       "0           0  0.999903  0.000097\n",
       "1           1  0.998371  0.001629\n",
       "2           2  0.999981  0.000019\n",
       "3           3  0.999989  0.000011\n",
       "4           4  0.998161  0.001839"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dacd5c",
   "metadata": {},
   "source": [
    "## Load Classifier into Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbfa17",
   "metadata": {},
   "source": [
    "Prediction models generated with CaTabRa can be easily loaded into a Python session. The easiest and most straight-forward way to do this is through the `catabra.io.CaTabRaLoader` class, which only needs to be instantiated with the directory containing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a34e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = io.CaTabRaLoader(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72f49e",
   "metadata": {},
   "source": [
    "The resulting class instance provides easy access to all sorts of artifacts generated by the functions above, in particular the trained classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35209e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loader.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f9bad",
   "metadata": {},
   "source": [
    "### Investigating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e2356",
   "metadata": {},
   "source": [
    "The type of the loaded `model` object depends on the AutoML backend used for training it, in this case auto-sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885faf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "catabra.automl.askl.backend.AutoSklearnBackend"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b085ac",
   "metadata": {},
   "source": [
    "If we want a uniform representation of the model independent of the AutoML backend, we can convert it into a `FittedEnsemble`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d49bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = model.fitted_ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd2087",
   "metadata": {},
   "source": [
    "A `FittedEnsemble` is, as its name suggests, an ensemble consisting of individual base models and a meta-estimator combining the predictions of the base models to a single output. These base models can be accessed via the `models_` attribute, which is a dict mapping model-IDs to instances of class `FittedModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ba7a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{55: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False,\n",
       "                                                                 strategy='most_frequent')),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   RobustScaler(copy=False,\n",
       "                                                                quantile_range=(0.13411318439233166,\n",
       "                                                                                0.880381628929301))),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(fun='exp', n_components=314, random_state=1)],\n",
       "     estimator=LinearSVC(C=0.6406426017332504, class_weight='balanced', dual=False,\n",
       "           intercept_scaling=1.0, random_state=1, tol=0.00012928412068849977)),\n",
       " 70: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False)),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   StandardScaler(copy=False)),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(algorithm='deflation', n_components=134, random_state=1)],\n",
       "     estimator=LinearSVC(C=0.037102666451776, class_weight='balanced', dual=False,\n",
       "           intercept_scaling=1.0, random_state=1, tol=7.012538595303216e-05)),\n",
       " 74: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False,\n",
       "                                                                 strategy='most_frequent')),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   RobustScaler(copy=False,\n",
       "                                                                quantile_range=(0.24439313931905698,\n",
       "                                                                                0.9527018660917124))),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(fun='exp', n_components=1324, random_state=1)],\n",
       "     estimator=LinearSVC(C=0.03694688108813779, dual=False, intercept_scaling=1.0,\n",
       "           random_state=1, tol=3.5388917975900854e-05)),\n",
       " 76: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False)),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   StandardScaler(copy=False)),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(algorithm='deflation', n_components=216, random_state=1)],\n",
       "     estimator=LinearSVC(C=0.18298402049436568, dual=False, intercept_scaling=1.0,\n",
       "           random_state=1, tol=2.0508587358230552e-05)),\n",
       " 48: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False)),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   StandardScaler(copy=False)),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(algorithm='deflation', fun='exp', n_components=104, random_state=1)],\n",
       "     estimator=LinearSVC(C=1.6256122240448774, dual=False, intercept_scaling=1.0,\n",
       "           random_state=1, tol=5.7569680509488696e-05)),\n",
       " 59: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False,\n",
       "                                                                 strategy='median')),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   RobustScaler(copy=False,\n",
       "                                                                quantile_range=(0.26413154772675485,\n",
       "                                                                                0.75))),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(algorithm='deflation', fun='exp', n_components=216, random_state=1)],\n",
       "     estimator=LinearSVC(C=1.6256122240448774, dual=False, intercept_scaling=1.0,\n",
       "           random_state=1, tol=1.0628097125906722e-05)),\n",
       " 12: FittedModel(\n",
       "     preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                   transformers=[('numerical_transformer',\n",
       "                                  Pipeline(steps=[('imputation',\n",
       "                                                   SimpleImputer(copy=False,\n",
       "                                                                 strategy='most_frequent')),\n",
       "                                                  ('variance_threshold',\n",
       "                                                   VarianceThreshold()),\n",
       "                                                  ('rescaling',\n",
       "                                                   RobustScaler(copy=False,\n",
       "                                                                quantile_range=(0.16271852122755062,\n",
       "                                                                                0.7278293151795671))),\n",
       "                                                  ('dummy', 'passthrough')]),\n",
       "                                  [True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True, True, True, True, True, True,\n",
       "                                   True, True])]), FastICA(algorithm='deflation', fun='exp', n_components=1631, random_state=1)],\n",
       "     estimator=PassiveAggressiveClassifier(C=0.008807665845919431, max_iter=128,\n",
       "                             random_state=1, tol=0.001174447028725537,\n",
       "                             warm_start=True))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803372fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FittedModel(\n",
       "    preprocessing=[ColumnTransformer(sparse_threshold=0.0,\n",
       "                  transformers=[('numerical_transformer',\n",
       "                                 Pipeline(steps=[('imputation',\n",
       "                                                  SimpleImputer(copy=False,\n",
       "                                                                strategy='most_frequent')),\n",
       "                                                 ('variance_threshold',\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 ('rescaling',\n",
       "                                                  RobustScaler(copy=False,\n",
       "                                                               quantile_range=(0.13411318439233166,\n",
       "                                                                               0.880381628929301))),\n",
       "                                                 ('dummy', 'passthrough')]),\n",
       "                                 [True, True, True, True, True, True, True,\n",
       "                                  True, True, True, True, True, True, True,\n",
       "                                  True, True, True, True, True, True, True,\n",
       "                                  True, True, True, True, True, True, True,\n",
       "                                  True, True])]), FastICA(fun='exp', n_components=314, random_state=1)],\n",
       "    estimator=LinearSVC(C=0.6406426017332504, class_weight='balanced', dual=False,\n",
       "          intercept_scaling=1.0, random_state=1, tol=0.00012928412068849977))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.models_[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477feb9",
   "metadata": {},
   "source": [
    "**NOTE**<br>\n",
    "Predictions returned by `fe` may deviate slightly from those of `model` due to a [known bug in auto-sklearn](https://github.com/automl/auto-sklearn/issues/1483)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccda3d",
   "metadata": {},
   "source": [
    "### Applying the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e290c",
   "metadata": {},
   "source": [
    "If we want to apply the model to new data, we first need to load the encoder that was constructed jointly with the model. Again, the `loader` object comes in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d2094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = loader.get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "830a30bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99903057e-01, 9.69427072e-05],\n",
       "       [9.98370982e-01, 1.62901758e-03],\n",
       "       [9.99981249e-01, 1.87510020e-05],\n",
       "       ...,\n",
       "       [9.67988655e-01, 3.20113446e-02],\n",
       "       [9.99999948e-01, 5.15996838e-08],\n",
       "       [2.80621887e-05, 9.99971938e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(encoder.transform(x=X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe624d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

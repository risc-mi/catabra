{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1eb0ad1",
   "metadata": {},
   "source": [
    "# Prediction Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc11d21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdeaa0",
   "metadata": {},
   "source": [
    "This notebook is part of the [CaTabRa GitHub repository](https://github.com/risc-mi/catabra)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edf725",
   "metadata": {},
   "source": [
    "This short example demonstrates the four prediction tasks supported by CaTabRa:\n",
    "\n",
    "* [binary classification](#Binary-Classification),\n",
    "* [multiclass classification](#Multiclass-Classification),\n",
    "* [multilabel classification](#Multilabel-Classification), and\n",
    "* [regression](#Regression).\n",
    "\n",
    "Familiarity with CaTabRa's main data analysis workflow is assumed. A step-by-step introduction can be found in [CaTabRa Workflow](https://catabra.readthedocs.io/en/latest/jupyter/workflow.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb38d6",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e8d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catabra.analysis import analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164105f0",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e2ba5",
   "metadata": {},
   "source": [
    "Analyze data with a binary target, i.e., each sample belongs to one of two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74be720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "X_binary, y_binary = load_breast_cancer(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa4bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target labels to DataFrame\n",
    "X_binary['diagnosis'] = y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a204657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train- and test set by adding column with corresponding values\n",
    "# the name of the column is arbitrary; CaTabRa tries to \"guess\" which samples belong to which set based on the column name and -values\n",
    "X_binary['train'] = X_binary.index <= 0.8 * len(X_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30566d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Analysis started at 2023-02-07 10:44:35.243270\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend auto-sklearn for binary_classification\n",
      "[CaTabRa] Successfully loaded the following auto-sklearn add-on module(s): xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaletzk/miniconda3/envs/catabra/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:68: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.metafeatures = self.metafeatures.append(metafeatures)\n",
      "/home/amaletzk/miniconda3/envs/catabra/lib/python3.9/site-packages/autosklearn/metalearning/metalearning/meta_base.py:72: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.algorithm_runs[metric].append(runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.980337\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:04\n",
      "[CaTabRa] New model #1 trained:\n",
      "    val_roc_auc: 0.980337\n",
      "    val_accuracy: 0.927152\n",
      "    val_balanced_accuracy: 0.928416\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:04\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:05\n",
      "[CaTabRa] New model #2 trained:\n",
      "    val_roc_auc: 0.994744\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.947717\n",
      "    train_roc_auc: 0.996970\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:05\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:06\n",
      "[CaTabRa] New model #3 trained:\n",
      "    val_roc_auc: 0.970098\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.915458\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:06\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:07\n",
      "[CaTabRa] New model #4 trained:\n",
      "    val_roc_auc: 0.975535\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.934034\n",
      "    train_roc_auc: 0.999866\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:07\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:09\n",
      "[CaTabRa] New model #5 trained:\n",
      "    val_roc_auc: 0.969192\n",
      "    val_accuracy: 0.913907\n",
      "    val_balanced_accuracy: 0.914734\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:09\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994744\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New model #6 trained:\n",
      "    val_roc_auc: 0.984143\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.934034\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.994926\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:12\n",
      "[CaTabRa] New model #7 trained:\n",
      "    val_roc_auc: 0.980065\n",
      "    val_accuracy: 0.907285\n",
      "    val_balanced_accuracy: 0.914009\n",
      "    train_roc_auc: 0.995322\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:12\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.995832\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:17\n",
      "[CaTabRa] New model #8 trained:\n",
      "    val_roc_auc: 0.994201\n",
      "    val_accuracy: 0.973510\n",
      "    val_balanced_accuracy: 0.972635\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:17\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.995832\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:19\n",
      "[CaTabRa] New model #9 trained:\n",
      "    val_roc_auc: 0.978434\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.926694\n",
      "    train_roc_auc: 0.998574\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:19\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.995832\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:21\n",
      "[CaTabRa] New model #10 trained:\n",
      "    val_roc_auc: 0.985502\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.937206\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:21\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New model #11 trained:\n",
      "    val_roc_auc: 0.997282\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.927419\n",
      "    train_roc_auc: 0.995901\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:24\n",
      "[CaTabRa] New model #12 trained:\n",
      "    val_roc_auc: 0.976260\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.925245\n",
      "    train_roc_auc: 0.998886\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:23\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:27\n",
      "[CaTabRa] New model #13 trained:\n",
      "    val_roc_auc: 0.995107\n",
      "    val_accuracy: 0.973510\n",
      "    val_balanced_accuracy: 0.972635\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:27\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:29\n",
      "[CaTabRa] New model #14 trained:\n",
      "    val_roc_auc: 0.994020\n",
      "    val_accuracy: 0.953642\n",
      "    val_balanced_accuracy: 0.948441\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:29\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:30\n",
      "[CaTabRa] New model #15 trained:\n",
      "    val_roc_auc: 0.987858\n",
      "    val_accuracy: 0.940397\n",
      "    val_balanced_accuracy: 0.942099\n",
      "    train_roc_auc: 1.000000\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:30\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:31\n",
      "[CaTabRa] New model #16 trained:\n",
      "    val_roc_auc: 0.994020\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.950163\n",
      "    train_roc_auc: 0.996569\n",
      "    type: sgd\n",
      "    total_elapsed_time: 00:31\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:32\n",
      "[CaTabRa] New model #17 trained:\n",
      "    val_roc_auc: 0.996557\n",
      "    val_accuracy: 0.966887\n",
      "    val_balanced_accuracy: 0.964570\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:32\n",
      "[CaTabRa] New model #18 trained:\n",
      "    val_roc_auc: 0.974175\n",
      "    val_accuracy: 0.920530\n",
      "    val_balanced_accuracy: 0.920352\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:33\n",
      "[CaTabRa] New model #19 trained:\n",
      "    val_roc_auc: 0.981877\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.934034\n",
      "    train_roc_auc: 0.999955\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:35\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:36\n",
      "[CaTabRa] New model #20 trained:\n",
      "    val_roc_auc: 0.987767\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.956506\n",
      "    train_roc_auc: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:36\n",
      "[CaTabRa] New model #21 trained:\n",
      "    val_roc_auc: 0.876858\n",
      "    val_accuracy: 0.880795\n",
      "    val_balanced_accuracy: 0.876858\n",
      "    train_roc_auc: 1.000000\n",
      "    type: k_nearest_neighbors\n",
      "    total_elapsed_time: 00:37\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:38\n",
      "[CaTabRa] New model #22 trained:\n",
      "    val_roc_auc: 0.988039\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.956506\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:38\n",
      "[CaTabRa] New model #23 trained:\n",
      "    val_roc_auc: 0.982331\n",
      "    val_accuracy: 0.913907\n",
      "    val_balanced_accuracy: 0.914734\n",
      "    train_roc_auc: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:39\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:40\n",
      "[CaTabRa] New model #24 trained:\n",
      "    val_roc_auc: 0.990395\n",
      "    val_accuracy: 0.960265\n",
      "    val_balanced_accuracy: 0.956506\n",
      "    train_roc_auc: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:40\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New model #25 trained:\n",
      "    val_roc_auc: 0.993838\n",
      "    val_accuracy: 0.933775\n",
      "    val_balanced_accuracy: 0.941374\n",
      "    train_roc_auc: 0.997995\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_roc_auc: 0.998007\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:47\n",
      "[CaTabRa] New model #26 trained:\n",
      "    val_roc_auc: 0.993295\n",
      "    val_accuracy: 0.947020\n",
      "    val_balanced_accuracy: 0.947717\n",
      "    train_roc_auc: 0.994386\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:47\n",
      "[CaTabRa] New model #27 trained:\n",
      "    val_roc_auc: 0.942008\n",
      "    val_accuracy: 0.741722\n",
      "    val_balanced_accuracy: 0.776006\n",
      "    train_roc_auc: 0.971039\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 27\n",
      "    ensemble_val_roc_auc: 0.9980065241029358\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type Autoencoder\n",
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "Iteration 1, loss = 0.06377027\n",
      "Iteration 2, loss = 0.03359140\n",
      "Iteration 3, loss = 0.02194009\n",
      "Iteration 4, loss = 0.01638331\n",
      "Iteration 5, loss = 0.01398731\n",
      "Iteration 6, loss = 0.01247938\n",
      "Iteration 7, loss = 0.01109453\n",
      "Iteration 8, loss = 0.01022823\n",
      "Iteration 9, loss = 0.00959181\n",
      "Iteration 10, loss = 0.00878776\n",
      "Iteration 11, loss = 0.00890786\n",
      "Iteration 12, loss = 0.00813948\n",
      "Iteration 13, loss = 0.00792689\n",
      "Iteration 14, loss = 0.00700066\n",
      "Iteration 15, loss = 0.00632195\n",
      "Iteration 16, loss = 0.00601902\n",
      "Iteration 17, loss = 0.00576786\n",
      "Iteration 18, loss = 0.00579422\n",
      "Iteration 19, loss = 0.00653422\n",
      "Iteration 20, loss = 0.00673960\n",
      "Iteration 21, loss = 0.00594721\n",
      "Iteration 22, loss = 0.00580508\n",
      "Iteration 23, loss = 0.00573597\n",
      "Iteration 24, loss = 0.00554276\n",
      "Iteration 25, loss = 0.00560443\n",
      "Iteration 26, loss = 0.00545064\n",
      "Iteration 27, loss = 0.00537846\n",
      "Iteration 28, loss = 0.00532150\n",
      "Iteration 29, loss = 0.00532396\n",
      "Iteration 30, loss = 0.00528569\n",
      "Iteration 31, loss = 0.00528335\n",
      "Iteration 32, loss = 0.00525824\n",
      "Iteration 33, loss = 0.00527302\n",
      "Iteration 34, loss = 0.00526580\n",
      "Iteration 35, loss = 0.00523524\n",
      "Iteration 36, loss = 0.00525581\n",
      "Iteration 37, loss = 0.00522755\n",
      "Iteration 38, loss = 0.00522458\n",
      "Iteration 39, loss = 0.00522368\n",
      "Iteration 40, loss = 0.00521142\n",
      "Iteration 41, loss = 0.00521995\n",
      "Iteration 42, loss = 0.00521802\n",
      "Iteration 43, loss = 0.00521297\n",
      "Iteration 44, loss = 0.00521383\n",
      "Iteration 45, loss = 0.00520886\n",
      "Iteration 46, loss = 0.00521189\n",
      "Iteration 47, loss = 0.00523315\n",
      "Iteration 48, loss = 0.00520962\n",
      "Iteration 49, loss = 0.00522331\n",
      "Iteration 50, loss = 0.00520331\n",
      "Iteration 51, loss = 0.00519715\n",
      "Iteration 52, loss = 0.00521778\n",
      "Iteration 53, loss = 0.00519735\n",
      "Iteration 54, loss = 0.00518522\n",
      "Iteration 55, loss = 0.00518577\n",
      "Iteration 56, loss = 0.00520093\n",
      "Iteration 57, loss = 0.00519632\n",
      "Iteration 58, loss = 0.00517685\n",
      "Iteration 59, loss = 0.00518872\n",
      "Iteration 60, loss = 0.00522378\n",
      "Iteration 61, loss = 0.00520782\n",
      "Iteration 62, loss = 0.00519619\n",
      "Iteration 63, loss = 0.00522216\n",
      "Iteration 64, loss = 0.00528045\n",
      "Iteration 65, loss = 0.00522250\n",
      "Iteration 66, loss = 0.00521136\n",
      "Iteration 67, loss = 0.00520125\n",
      "Iteration 68, loss = 0.00517974\n",
      "Iteration 69, loss = 0.00516680\n",
      "Iteration 70, loss = 0.00516050\n",
      "Iteration 71, loss = 0.00516956\n",
      "Iteration 72, loss = 0.00516102\n",
      "Iteration 73, loss = 0.00524152\n",
      "Iteration 74, loss = 0.00517434\n",
      "Iteration 75, loss = 0.00529929\n",
      "Training loss did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-02-07 10:45:35.313517\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:01:00.070247\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification\n",
      "[CaTabRa] ### Evaluation started at 2023-02-07 10:45:35.376897\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    roc_auc: 0.9973715651135006\n",
      "    accuracy @ 0.5: 0.9736842105263158\n",
      "    balanced_accuracy @ 0.5: 0.96857825567503\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    roc_auc: 0.9986737400530503\n",
      "    accuracy @ 0.5: 0.9734513274336283\n",
      "    balanced_accuracy @ 0.5: 0.95579133510168\n",
      "[CaTabRa] ### Evaluation finished at 2023-02-07 10:45:40.180348\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:04.803451\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/binary_classification/eval\n"
     ]
    }
   ],
   "source": [
    "analyze(\n",
    "    X_binary,                 # table to analyze; can also be the path to a CSV/Excel/HDF5 file\n",
    "    classify='diagnosis',     # name of column containing classification target\n",
    "    split='train',            # name of column containing information about the train-test split (optional)\n",
    "    time=1,                   # time budget for hyperparameter tuning, in minutes (optional)\n",
    "    out='binary_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00280bd",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6c2c0",
   "metadata": {},
   "source": [
    "Analyze data with a multiclass target, i.e., each sample belongs to one of `n > 2` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "604d27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import load_iris\n",
    "X_multiclass, y_multiclass = load_iris(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd66a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target labels to DataFrame\n",
    "X_multiclass['species'] = y_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3544ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train- and test set by adding column with corresponding values\n",
    "# the name of the column is arbitrary; CaTabRa tries to \"guess\" which samples belong to which set based on the column name and -values\n",
    "X_multiclass['test'] = np.random.choice([False, True], size=len(X_multiclass), p=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed0545b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  ...  species   test\n",
       "0                5.1               3.5  ...        0   True\n",
       "1                4.9               3.0  ...        0  False\n",
       "2                4.7               3.2  ...        0  False\n",
       "3                4.6               3.1  ...        0  False\n",
       "4                5.0               3.6  ...        0   True\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multiclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "848e85dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multiclass['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "526a7c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>species</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "species   0   1   2\n",
       "test               \n",
       "False    36  39  40\n",
       "True     14  11  10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multiclass.groupby('test')['species'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286eda6e",
   "metadata": {},
   "source": [
    "Function `analyze()` is called just as before. CaTabRa automatically treats the given data as multiclass, because the target column specified by `classify` contains more than two unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c88f8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder \"/mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/multiclass_classification\" already exists. Delete? [y/n] y\n",
      "[CaTabRa] ### Analysis started at 2023-02-07 10:52:44.468626\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend auto-sklearn for multiclass_classification\n",
      "[CaTabRa] Successfully loaded the following auto-sklearn add-on module(s): xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 0.973684\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:05\n",
      "[CaTabRa] New model #1 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:05\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 0.973684\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:07\n",
      "[CaTabRa] New model #2 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:07\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 0.973684\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:07\n",
      "[CaTabRa] New model #3 trained:\n",
      "    val_accuracy: 0.868421\n",
      "    val_balanced_accuracy: 0.871795\n",
      "    train_accuracy: 0.883117\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:07\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 0.973684\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:08\n",
      "[CaTabRa] New model #4 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.974026\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:08\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 0.973684\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New model #5 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New model #6 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: libsvm_svc\n",
      "    total_elapsed_time: 00:10\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 00:12\n",
      "[CaTabRa] New model #7 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:12\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 00:13\n",
      "[CaTabRa] New model #8 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.974026\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:13\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 00:14\n",
      "[CaTabRa] New model #9 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:14\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 00:14\n",
      "[CaTabRa] New model #10 trained:\n",
      "    val_accuracy: 1.000000\n",
      "    val_balanced_accuracy: 1.000000\n",
      "    train_accuracy: 0.987013\n",
      "    type: decision_tree\n",
      "    total_elapsed_time: 00:14\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 6\n",
      "    total_elapsed_time: 00:15\n",
      "[CaTabRa] New model #11 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:15\n",
      "[CaTabRa] New model #12 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 00:16\n",
      "[CaTabRa] New model #13 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.974026\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:17\n",
      "[CaTabRa] New model #14 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:18\n",
      "[CaTabRa] New model #15 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.974026\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:19\n",
      "[CaTabRa] New model #16 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: adaboost\n",
      "    total_elapsed_time: 00:21\n",
      "[CaTabRa] New model #17 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New model #18 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:23\n",
      "[CaTabRa] New model #19 trained:\n",
      "    val_accuracy: 0.842105\n",
      "    val_balanced_accuracy: 0.846154\n",
      "    train_accuracy: 0.909091\n",
      "    type: passive_aggressive\n",
      "    total_elapsed_time: 00:23\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 7\n",
      "    total_elapsed_time: 00:25\n",
      "[CaTabRa] New model #20 trained:\n",
      "    val_accuracy: 1.000000\n",
      "    val_balanced_accuracy: 1.000000\n",
      "    train_accuracy: 0.987013\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:25\n",
      "[CaTabRa] New model #21 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:26\n",
      "[CaTabRa] New model #22 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:27\n",
      "[CaTabRa] New model #23 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.974026\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:28\n",
      "[CaTabRa] New model #24 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.974026\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:30\n",
      "[CaTabRa] New model #25 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:31\n",
      "[WARNING] [2023-02-07 10:53:17,557:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_accuracy: 1.000000\n",
      "    n_constituent_models: 7\n",
      "    total_elapsed_time: 00:35\n",
      "[CaTabRa] New model #26 trained:\n",
      "    val_accuracy: 1.000000\n",
      "    val_balanced_accuracy: 1.000000\n",
      "    train_accuracy: 1.000000\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:35\n",
      "[WARNING] [2023-02-07 10:53:21,478:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
      "[CaTabRa] New model #27 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.961039\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:39\n",
      "[WARNING] [2023-02-07 10:53:25,091:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
      "[CaTabRa] New model #28 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.987013\n",
      "    type: decision_tree\n",
      "    total_elapsed_time: 00:42\n",
      "[WARNING] [2023-02-07 10:53:28,507:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
      "[CaTabRa] New model #29 trained:\n",
      "    val_accuracy: 0.657895\n",
      "    val_balanced_accuracy: 0.666667\n",
      "    train_accuracy: 0.649351\n",
      "    type: decision_tree\n",
      "    total_elapsed_time: 00:45\n",
      "[WARNING] [2023-02-07 10:53:31,791:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
      "[CaTabRa] New model #30 trained:\n",
      "    val_accuracy: 0.684211\n",
      "    val_balanced_accuracy: 0.685897\n",
      "    train_accuracy: 0.727273\n",
      "    type: qda\n",
      "    total_elapsed_time: 00:46\n",
      "[WARNING] [2023-02-07 10:53:32,555:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
      "[CaTabRa] New model #31 trained:\n",
      "    val_accuracy: 0.973684\n",
      "    val_balanced_accuracy: 0.974359\n",
      "    train_accuracy: 0.935065\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:50\n",
      "[WARNING] [2023-02-07 10:53:36,301:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 31\n",
      "    ensemble_val_accuracy: 1.0\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type Autoencoder\n",
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "Iteration 1, loss = 1.61104467\n",
      "Iteration 2, loss = 1.43654067\n",
      "Iteration 3, loss = 1.27854978\n",
      "Iteration 4, loss = 1.13614818\n",
      "Iteration 5, loss = 1.00836412\n",
      "Iteration 6, loss = 0.89419353\n",
      "Iteration 7, loss = 0.79261599\n",
      "Iteration 8, loss = 0.70261024\n",
      "Iteration 9, loss = 0.62316871\n",
      "Iteration 10, loss = 0.55331055\n",
      "Iteration 11, loss = 0.49209276\n",
      "Iteration 12, loss = 0.43861932\n",
      "Iteration 13, loss = 0.39204793\n",
      "Iteration 14, loss = 0.35159479\n",
      "Iteration 15, loss = 0.31653725\n",
      "Iteration 16, loss = 0.28621472\n",
      "Iteration 17, loss = 0.26002813\n",
      "Iteration 18, loss = 0.23743812\n",
      "Iteration 19, loss = 0.21796231\n",
      "Iteration 20, loss = 0.20117202\n",
      "Iteration 21, loss = 0.18668841\n",
      "Iteration 22, loss = 0.17417852\n",
      "Iteration 23, loss = 0.16349008\n",
      "Iteration 24, loss = 0.15395270\n",
      "Iteration 25, loss = 0.14576417\n",
      "Iteration 26, loss = 0.13859644\n",
      "Iteration 27, loss = 0.13228710\n",
      "Iteration 28, loss = 0.12669742\n",
      "Iteration 29, loss = 0.12170941\n",
      "Iteration 30, loss = 0.11722327\n",
      "Iteration 31, loss = 0.11315493\n",
      "Iteration 32, loss = 0.10943403\n",
      "Iteration 33, loss = 0.10600198\n",
      "Iteration 34, loss = 0.10281034\n",
      "Iteration 35, loss = 0.09981932\n",
      "Iteration 36, loss = 0.09699653\n",
      "Iteration 37, loss = 0.09431581\n",
      "Iteration 38, loss = 0.09175631\n",
      "Iteration 39, loss = 0.08930155\n",
      "Iteration 40, loss = 0.08693878\n",
      "Iteration 41, loss = 0.08465825\n",
      "Iteration 42, loss = 0.08245272\n",
      "Iteration 43, loss = 0.08031693\n",
      "Iteration 44, loss = 0.07824726\n",
      "Iteration 45, loss = 0.07624131\n",
      "Iteration 46, loss = 0.07429766\n",
      "Iteration 47, loss = 0.07241559\n",
      "Iteration 48, loss = 0.07059486\n",
      "Iteration 49, loss = 0.06883559\n",
      "Iteration 50, loss = 0.06713804\n",
      "Iteration 51, loss = 0.06550254\n",
      "Iteration 52, loss = 0.06392941\n",
      "Iteration 53, loss = 0.06241882\n",
      "Iteration 54, loss = 0.06097080\n",
      "Iteration 55, loss = 0.05958518\n",
      "Iteration 56, loss = 0.05826153\n",
      "Iteration 57, loss = 0.05699920\n",
      "Iteration 58, loss = 0.05579728\n",
      "Iteration 59, loss = 0.05465461\n",
      "Iteration 60, loss = 0.05356982\n",
      "Iteration 61, loss = 0.05254128\n",
      "Iteration 62, loss = 0.05156719\n",
      "Iteration 63, loss = 0.05064558\n",
      "Iteration 64, loss = 0.04977432\n",
      "Iteration 65, loss = 0.04895119\n",
      "Iteration 66, loss = 0.04817387\n",
      "Iteration 67, loss = 0.04743998\n",
      "Iteration 68, loss = 0.04674713\n",
      "Iteration 69, loss = 0.04609293\n",
      "Iteration 70, loss = 0.04547500\n",
      "Iteration 71, loss = 0.04489103\n",
      "Iteration 72, loss = 0.04433879\n",
      "Iteration 73, loss = 0.04381610\n",
      "Iteration 74, loss = 0.04332094\n",
      "Iteration 75, loss = 0.04285135\n",
      "Iteration 76, loss = 0.04240554\n",
      "Iteration 77, loss = 0.04198182\n",
      "Iteration 78, loss = 0.04157865\n",
      "Iteration 79, loss = 0.04119461\n",
      "Iteration 80, loss = 0.04082844\n",
      "Iteration 81, loss = 0.04047897\n",
      "Iteration 82, loss = 0.04014516\n",
      "Iteration 83, loss = 0.03982611\n",
      "Iteration 84, loss = 0.03952099\n",
      "Iteration 85, loss = 0.03922909\n",
      "Iteration 86, loss = 0.03894978\n",
      "Iteration 87, loss = 0.03868249\n",
      "Iteration 88, loss = 0.03842674\n",
      "Iteration 89, loss = 0.03818209\n",
      "Iteration 90, loss = 0.03794816\n",
      "Iteration 91, loss = 0.03772459\n",
      "Iteration 92, loss = 0.03751107\n",
      "Iteration 93, loss = 0.03730730\n",
      "Iteration 94, loss = 0.03711299\n",
      "Iteration 95, loss = 0.03692789\n",
      "Iteration 96, loss = 0.03675174\n",
      "Iteration 97, loss = 0.03658426\n",
      "Iteration 98, loss = 0.03642521\n",
      "Iteration 99, loss = 0.03627433\n",
      "Iteration 100, loss = 0.03613136\n",
      "Iteration 101, loss = 0.03599602\n",
      "Iteration 102, loss = 0.03586806\n",
      "Iteration 103, loss = 0.03574719\n",
      "Iteration 104, loss = 0.03563315\n",
      "Iteration 105, loss = 0.03552564\n",
      "Iteration 106, loss = 0.03542441\n",
      "Iteration 107, loss = 0.03532915\n",
      "Iteration 108, loss = 0.03523961\n",
      "Iteration 109, loss = 0.03515549\n",
      "Iteration 110, loss = 0.03507654\n",
      "Iteration 111, loss = 0.03500249\n",
      "Iteration 112, loss = 0.03493308\n",
      "Iteration 113, loss = 0.03486805\n",
      "Iteration 114, loss = 0.03480716\n",
      "Iteration 115, loss = 0.03475019\n",
      "Iteration 116, loss = 0.03469690\n",
      "Iteration 117, loss = 0.03464708\n",
      "Iteration 118, loss = 0.03460052\n",
      "Iteration 119, loss = 0.03455703\n",
      "Iteration 120, loss = 0.03451642\n",
      "Iteration 121, loss = 0.03447853\n",
      "Iteration 122, loss = 0.03444317\n",
      "Iteration 123, loss = 0.03441021\n",
      "Iteration 124, loss = 0.03437948\n",
      "Iteration 125, loss = 0.03435085\n",
      "Iteration 126, loss = 0.03432420\n",
      "Iteration 127, loss = 0.03429939\n",
      "Iteration 128, loss = 0.03427632\n",
      "Iteration 129, loss = 0.03425488\n",
      "Iteration 130, loss = 0.03423495\n",
      "Iteration 131, loss = 0.03421646\n",
      "Iteration 132, loss = 0.03419930\n",
      "Iteration 133, loss = 0.03418339\n",
      "Iteration 134, loss = 0.03416866\n",
      "Iteration 135, loss = 0.03415502\n",
      "Iteration 136, loss = 0.03414240\n",
      "Iteration 137, loss = 0.03413074\n",
      "Iteration 138, loss = 0.03411998\n",
      "Iteration 139, loss = 0.03411005\n",
      "Iteration 140, loss = 0.03410089\n",
      "Iteration 141, loss = 0.03409246\n",
      "Iteration 142, loss = 0.03408469\n",
      "Iteration 143, loss = 0.03407756\n",
      "Iteration 144, loss = 0.03407100\n",
      "Iteration 145, loss = 0.03406497\n",
      "Iteration 146, loss = 0.03405945\n",
      "Iteration 147, loss = 0.03405439\n",
      "Iteration 148, loss = 0.03404975\n",
      "Iteration 149, loss = 0.03404550\n",
      "Iteration 150, loss = 0.03404162\n",
      "Iteration 151, loss = 0.03403807\n",
      "Iteration 152, loss = 0.03403483\n",
      "Iteration 153, loss = 0.03403188\n",
      "Iteration 154, loss = 0.03402918\n",
      "Iteration 155, loss = 0.03402672\n",
      "Iteration 156, loss = 0.03402448\n",
      "Iteration 157, loss = 0.03402245\n",
      "Training loss did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-02-07 10:53:49.727518\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:01:05.258892\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/multiclass_classification\n",
      "[CaTabRa] ### Evaluation started at 2023-02-07 10:53:49.730334\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Evaluation results for not_test:\n",
      "    accuracy: 0.991304347826087\n",
      "    balanced_accuracy: 0.9914529914529915\n",
      "[CaTabRa] Evaluation results for test:\n",
      "    accuracy: 0.9428571428571428\n",
      "    balanced_accuracy: 0.9393939393939394\n",
      "[CaTabRa] ### Evaluation finished at 2023-02-07 10:53:52.687656\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:02.957322\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/multiclass_classification/eval\n"
     ]
    }
   ],
   "source": [
    "analyze(\n",
    "    X_multiclass,             # table to analyze; can also be the path to a CSV/Excel/HDF5 file\n",
    "    classify='species',       # name of column containing classification target\n",
    "    split='test',             # name of column containing information about the train-test split (optional)\n",
    "    time=1,                   # time budget for hyperparameter tuning, in minutes (optional)\n",
    "    out='multiclass_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b28b1a",
   "metadata": {},
   "source": [
    "Note how the performance metrics reported during training differ from those in binary classification. This is also reflected in the detailed performance reports in subdirectory `eval/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de9ac4",
   "metadata": {},
   "source": [
    "## Multilabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547d469",
   "metadata": {},
   "source": [
    "Analyze data with a multilabel target, i.e., each sample belongs to an arbitrary subset of `n >= 2` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e49349f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "X_multilabel, y_multilabel = fetch_openml(data_id=40595, as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a36fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target labels to DataFrame\n",
    "X_multilabel = X_multilabel.join(y_multilabel == 'TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1dd7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train- and test set by adding column with corresponding values\n",
    "# the name of the column is arbitrary; CaTabRa tries to \"guess\" which samples belong to which set based on the column name and -values\n",
    "X_multilabel['train'] = X_multilabel.index <= 0.8 * len(X_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3af26038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Att1</th>\n",
       "      <th>Att2</th>\n",
       "      <th>Att3</th>\n",
       "      <th>Att4</th>\n",
       "      <th>Att5</th>\n",
       "      <th>Att6</th>\n",
       "      <th>Att7</th>\n",
       "      <th>Att8</th>\n",
       "      <th>Att9</th>\n",
       "      <th>Att10</th>\n",
       "      <th>Att11</th>\n",
       "      <th>Att12</th>\n",
       "      <th>Att13</th>\n",
       "      <th>Att14</th>\n",
       "      <th>Att15</th>\n",
       "      <th>Att16</th>\n",
       "      <th>Att17</th>\n",
       "      <th>Att18</th>\n",
       "      <th>Att19</th>\n",
       "      <th>Att20</th>\n",
       "      <th>Att21</th>\n",
       "      <th>Att22</th>\n",
       "      <th>Att23</th>\n",
       "      <th>Att24</th>\n",
       "      <th>Att25</th>\n",
       "      <th>Att26</th>\n",
       "      <th>Att27</th>\n",
       "      <th>Att28</th>\n",
       "      <th>Att29</th>\n",
       "      <th>Att30</th>\n",
       "      <th>Att31</th>\n",
       "      <th>Att32</th>\n",
       "      <th>Att33</th>\n",
       "      <th>Att34</th>\n",
       "      <th>Att35</th>\n",
       "      <th>Att36</th>\n",
       "      <th>Att37</th>\n",
       "      <th>Att38</th>\n",
       "      <th>Att39</th>\n",
       "      <th>Att40</th>\n",
       "      <th>...</th>\n",
       "      <th>Att262</th>\n",
       "      <th>Att263</th>\n",
       "      <th>Att264</th>\n",
       "      <th>Att265</th>\n",
       "      <th>Att266</th>\n",
       "      <th>Att267</th>\n",
       "      <th>Att268</th>\n",
       "      <th>Att269</th>\n",
       "      <th>Att270</th>\n",
       "      <th>Att271</th>\n",
       "      <th>Att272</th>\n",
       "      <th>Att273</th>\n",
       "      <th>Att274</th>\n",
       "      <th>Att275</th>\n",
       "      <th>Att276</th>\n",
       "      <th>Att277</th>\n",
       "      <th>Att278</th>\n",
       "      <th>Att279</th>\n",
       "      <th>Att280</th>\n",
       "      <th>Att281</th>\n",
       "      <th>Att282</th>\n",
       "      <th>Att283</th>\n",
       "      <th>Att284</th>\n",
       "      <th>Att285</th>\n",
       "      <th>Att286</th>\n",
       "      <th>Att287</th>\n",
       "      <th>Att288</th>\n",
       "      <th>Att289</th>\n",
       "      <th>Att290</th>\n",
       "      <th>Att291</th>\n",
       "      <th>Att292</th>\n",
       "      <th>Att293</th>\n",
       "      <th>Att294</th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Field</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Urban</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.666435</td>\n",
       "      <td>0.685047</td>\n",
       "      <td>0.699053</td>\n",
       "      <td>0.652746</td>\n",
       "      <td>0.407864</td>\n",
       "      <td>0.150309</td>\n",
       "      <td>0.535193</td>\n",
       "      <td>0.555689</td>\n",
       "      <td>0.580782</td>\n",
       "      <td>0.577094</td>\n",
       "      <td>0.390455</td>\n",
       "      <td>0.242458</td>\n",
       "      <td>0.170217</td>\n",
       "      <td>0.421797</td>\n",
       "      <td>0.428206</td>\n",
       "      <td>0.428277</td>\n",
       "      <td>0.490017</td>\n",
       "      <td>0.459252</td>\n",
       "      <td>0.350897</td>\n",
       "      <td>0.255987</td>\n",
       "      <td>0.310109</td>\n",
       "      <td>0.375018</td>\n",
       "      <td>0.437369</td>\n",
       "      <td>0.451752</td>\n",
       "      <td>0.508325</td>\n",
       "      <td>0.467347</td>\n",
       "      <td>0.567068</td>\n",
       "      <td>0.546262</td>\n",
       "      <td>0.566969</td>\n",
       "      <td>0.612951</td>\n",
       "      <td>0.621101</td>\n",
       "      <td>0.653561</td>\n",
       "      <td>0.694546</td>\n",
       "      <td>0.574777</td>\n",
       "      <td>0.710196</td>\n",
       "      <td>0.614510</td>\n",
       "      <td>0.590450</td>\n",
       "      <td>0.508313</td>\n",
       "      <td>0.645884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136652</td>\n",
       "      <td>0.136285</td>\n",
       "      <td>0.127585</td>\n",
       "      <td>0.249868</td>\n",
       "      <td>0.545665</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.261571</td>\n",
       "      <td>0.203095</td>\n",
       "      <td>0.172747</td>\n",
       "      <td>0.239030</td>\n",
       "      <td>0.309251</td>\n",
       "      <td>0.090241</td>\n",
       "      <td>0.048767</td>\n",
       "      <td>0.085062</td>\n",
       "      <td>0.072274</td>\n",
       "      <td>0.167601</td>\n",
       "      <td>0.094636</td>\n",
       "      <td>0.258751</td>\n",
       "      <td>0.092845</td>\n",
       "      <td>0.477150</td>\n",
       "      <td>0.224848</td>\n",
       "      <td>0.102568</td>\n",
       "      <td>0.329816</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.049615</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>0.653879</td>\n",
       "      <td>0.354982</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.247298</td>\n",
       "      <td>0.014025</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770156</td>\n",
       "      <td>0.767255</td>\n",
       "      <td>0.761053</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.688086</td>\n",
       "      <td>0.708416</td>\n",
       "      <td>0.757351</td>\n",
       "      <td>0.760633</td>\n",
       "      <td>0.740314</td>\n",
       "      <td>0.513377</td>\n",
       "      <td>0.600421</td>\n",
       "      <td>0.542340</td>\n",
       "      <td>0.439594</td>\n",
       "      <td>0.604272</td>\n",
       "      <td>0.624697</td>\n",
       "      <td>0.642823</td>\n",
       "      <td>0.424883</td>\n",
       "      <td>0.448578</td>\n",
       "      <td>0.318076</td>\n",
       "      <td>0.209851</td>\n",
       "      <td>0.570696</td>\n",
       "      <td>0.599071</td>\n",
       "      <td>0.556610</td>\n",
       "      <td>0.556215</td>\n",
       "      <td>0.653352</td>\n",
       "      <td>0.559962</td>\n",
       "      <td>0.473784</td>\n",
       "      <td>0.636677</td>\n",
       "      <td>0.653249</td>\n",
       "      <td>0.621813</td>\n",
       "      <td>0.613890</td>\n",
       "      <td>0.596795</td>\n",
       "      <td>0.596297</td>\n",
       "      <td>0.692224</td>\n",
       "      <td>0.634007</td>\n",
       "      <td>0.605896</td>\n",
       "      <td>0.594992</td>\n",
       "      <td>0.650470</td>\n",
       "      <td>0.582844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097577</td>\n",
       "      <td>0.167246</td>\n",
       "      <td>0.193839</td>\n",
       "      <td>0.283507</td>\n",
       "      <td>0.190554</td>\n",
       "      <td>0.072342</td>\n",
       "      <td>0.111906</td>\n",
       "      <td>0.175488</td>\n",
       "      <td>0.178064</td>\n",
       "      <td>0.249890</td>\n",
       "      <td>0.085085</td>\n",
       "      <td>0.073259</td>\n",
       "      <td>0.133331</td>\n",
       "      <td>0.090761</td>\n",
       "      <td>0.138334</td>\n",
       "      <td>0.102932</td>\n",
       "      <td>0.406639</td>\n",
       "      <td>0.126982</td>\n",
       "      <td>0.046562</td>\n",
       "      <td>0.354085</td>\n",
       "      <td>0.199359</td>\n",
       "      <td>0.157326</td>\n",
       "      <td>0.051859</td>\n",
       "      <td>0.114123</td>\n",
       "      <td>0.160008</td>\n",
       "      <td>0.414088</td>\n",
       "      <td>0.361843</td>\n",
       "      <td>0.303399</td>\n",
       "      <td>0.176387</td>\n",
       "      <td>0.251454</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.082672</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793984</td>\n",
       "      <td>0.772096</td>\n",
       "      <td>0.761820</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>0.740569</td>\n",
       "      <td>0.734361</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.849128</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>0.785767</td>\n",
       "      <td>0.760288</td>\n",
       "      <td>0.751835</td>\n",
       "      <td>0.754508</td>\n",
       "      <td>0.853808</td>\n",
       "      <td>0.857499</td>\n",
       "      <td>0.858505</td>\n",
       "      <td>0.864827</td>\n",
       "      <td>0.865957</td>\n",
       "      <td>0.867185</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.955915</td>\n",
       "      <td>0.966291</td>\n",
       "      <td>0.968941</td>\n",
       "      <td>0.879657</td>\n",
       "      <td>0.716114</td>\n",
       "      <td>0.479571</td>\n",
       "      <td>0.402155</td>\n",
       "      <td>0.754620</td>\n",
       "      <td>0.775176</td>\n",
       "      <td>0.723823</td>\n",
       "      <td>0.676656</td>\n",
       "      <td>0.633313</td>\n",
       "      <td>0.552341</td>\n",
       "      <td>0.417900</td>\n",
       "      <td>0.622198</td>\n",
       "      <td>0.652387</td>\n",
       "      <td>0.648123</td>\n",
       "      <td>0.680452</td>\n",
       "      <td>0.662322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060296</td>\n",
       "      <td>0.058945</td>\n",
       "      <td>0.052964</td>\n",
       "      <td>0.062245</td>\n",
       "      <td>0.075563</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.181837</td>\n",
       "      <td>0.213608</td>\n",
       "      <td>0.122532</td>\n",
       "      <td>0.035184</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.353377</td>\n",
       "      <td>0.073733</td>\n",
       "      <td>0.048943</td>\n",
       "      <td>0.080248</td>\n",
       "      <td>0.074113</td>\n",
       "      <td>0.051372</td>\n",
       "      <td>0.024035</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.028559</td>\n",
       "      <td>0.047596</td>\n",
       "      <td>0.038082</td>\n",
       "      <td>0.079977</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938563</td>\n",
       "      <td>0.949260</td>\n",
       "      <td>0.955621</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.953460</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>0.972766</td>\n",
       "      <td>0.916497</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.530428</td>\n",
       "      <td>0.963539</td>\n",
       "      <td>0.972303</td>\n",
       "      <td>0.972980</td>\n",
       "      <td>0.945388</td>\n",
       "      <td>0.609497</td>\n",
       "      <td>0.514073</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.804240</td>\n",
       "      <td>0.827367</td>\n",
       "      <td>0.813407</td>\n",
       "      <td>0.796413</td>\n",
       "      <td>0.753638</td>\n",
       "      <td>0.696435</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.782931</td>\n",
       "      <td>0.774347</td>\n",
       "      <td>0.750613</td>\n",
       "      <td>0.706845</td>\n",
       "      <td>0.612971</td>\n",
       "      <td>0.647101</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.736683</td>\n",
       "      <td>0.719352</td>\n",
       "      <td>0.643989</td>\n",
       "      <td>0.705878</td>\n",
       "      <td>0.773725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.093743</td>\n",
       "      <td>0.105665</td>\n",
       "      <td>0.060825</td>\n",
       "      <td>0.025972</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>0.448542</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>0.045848</td>\n",
       "      <td>0.020989</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.209978</td>\n",
       "      <td>0.138788</td>\n",
       "      <td>0.031173</td>\n",
       "      <td>0.032565</td>\n",
       "      <td>0.034237</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>0.082271</td>\n",
       "      <td>0.201563</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.027527</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.036799</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.524684</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.471209</td>\n",
       "      <td>0.417654</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>0.570074</td>\n",
       "      <td>0.551043</td>\n",
       "      <td>0.503925</td>\n",
       "      <td>0.447526</td>\n",
       "      <td>0.500117</td>\n",
       "      <td>0.539517</td>\n",
       "      <td>0.588721</td>\n",
       "      <td>0.600226</td>\n",
       "      <td>0.588937</td>\n",
       "      <td>0.562027</td>\n",
       "      <td>0.510786</td>\n",
       "      <td>0.465298</td>\n",
       "      <td>0.626580</td>\n",
       "      <td>0.649661</td>\n",
       "      <td>0.629969</td>\n",
       "      <td>0.574756</td>\n",
       "      <td>0.519651</td>\n",
       "      <td>0.445292</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>0.742275</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>0.903786</td>\n",
       "      <td>0.834243</td>\n",
       "      <td>0.766266</td>\n",
       "      <td>0.657113</td>\n",
       "      <td>0.276264</td>\n",
       "      <td>0.394086</td>\n",
       "      <td>0.610411</td>\n",
       "      <td>0.698119</td>\n",
       "      <td>0.743710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595821</td>\n",
       "      <td>0.207690</td>\n",
       "      <td>0.028206</td>\n",
       "      <td>0.010644</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.138157</td>\n",
       "      <td>0.094097</td>\n",
       "      <td>0.044848</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>0.090652</td>\n",
       "      <td>0.086531</td>\n",
       "      <td>0.293732</td>\n",
       "      <td>0.221770</td>\n",
       "      <td>0.094467</td>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.186763</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.043375</td>\n",
       "      <td>0.208570</td>\n",
       "      <td>0.188324</td>\n",
       "      <td>0.413413</td>\n",
       "      <td>0.387559</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>0.167709</td>\n",
       "      <td>0.226580</td>\n",
       "      <td>0.218534</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Att1      Att2      Att3      Att4  ...  Field  Mountain  Urban  train\n",
       "0  0.646467  0.666435  0.685047  0.699053  ...  False      True  False   True\n",
       "1  0.770156  0.767255  0.761053  0.745630  ...  False     False   True   True\n",
       "2  0.793984  0.772096  0.761820  0.762213  ...  False     False  False   True\n",
       "3  0.938563  0.949260  0.955621  0.966743  ...  False     False  False   True\n",
       "4  0.512130  0.524684  0.520020  0.504467  ...  False     False  False   True\n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multilabel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a53a4d",
   "metadata": {},
   "source": [
    "Function `analyze()` is called just as before, with more than one column passed to `classify`. This tells CaTabRa to treat the data as multilabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd12aeea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Analysis started at 2023-02-07 11:16:46.333073\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend auto-sklearn for multilabel_classification\n",
      "[CaTabRa] Successfully loaded the following auto-sklearn add-on module(s): xgb\n",
      "[WARNING] [2023-02-07 11:17:00,572:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 28 not found\n",
      "[WARNING] [2023-02-07 11:17:00,572:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 265 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 7 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 220 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 253 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 355 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 694 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 40 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 668 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 579 not found\n",
      "[WARNING] [2023-02-07 11:17:00,573:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 422 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 546 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 702 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 270 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 657 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 238 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 206 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 377 not found\n",
      "[WARNING] [2023-02-07 11:17:00,574:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 341 not found\n",
      "[WARNING] [2023-02-07 11:17:00,575:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 235 not found\n",
      "[WARNING] [2023-02-07 11:17:00,575:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 332 not found\n",
      "[WARNING] [2023-02-07 11:17:00,575:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 61 not found\n",
      "[WARNING] [2023-02-07 11:17:00,575:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 690 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 608 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 666 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 367 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 426 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 262 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 302 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 282 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 211 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 701 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 444 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 506 not found\n",
      "[WARNING] [2023-02-07 11:17:00,576:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 108 not found\n",
      "[WARNING] [2023-02-07 11:17:00,577:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 460 not found\n",
      "[WARNING] [2023-02-07 11:17:00,577:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 329 not found\n",
      "[WARNING] [2023-02-07 11:17:00,577:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 617 not found\n",
      "[WARNING] [2023-02-07 11:17:00,577:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 68 not found\n",
      "[WARNING] [2023-02-07 11:17:00,577:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 143 not found\n",
      "[WARNING] [2023-02-07 11:17:00,578:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 532 not found\n",
      "[WARNING] [2023-02-07 11:17:00,578:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 659 not found\n",
      "[WARNING] [2023-02-07 11:17:00,578:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 230 not found\n",
      "[WARNING] [2023-02-07 11:17:00,579:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 138 not found\n",
      "[WARNING] [2023-02-07 11:17:00,579:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 75 not found\n",
      "[WARNING] [2023-02-07 11:17:00,579:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 521 not found\n",
      "[WARNING] [2023-02-07 11:17:00,579:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 89 not found\n",
      "[WARNING] [2023-02-07 11:17:00,579:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 315 not found\n",
      "[WARNING] [2023-02-07 11:17:00,580:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 345 not found\n",
      "[WARNING] [2023-02-07 11:17:00,580:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 194 not found\n",
      "[WARNING] [2023-02-07 11:17:00,580:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 14 not found\n",
      "[WARNING] [2023-02-07 11:17:00,580:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 358 not found\n",
      "[WARNING] [2023-02-07 11:17:00,580:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 594 not found\n",
      "[WARNING] [2023-02-07 11:17:00,581:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 129 not found\n",
      "[WARNING] [2023-02-07 11:17:00,581:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 65 not found\n",
      "[WARNING] [2023-02-07 11:17:00,581:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 83 not found\n",
      "[WARNING] [2023-02-07 11:17:00,581:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 227 not found\n",
      "[WARNING] [2023-02-07 11:17:00,581:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 605 not found\n",
      "[WARNING] [2023-02-07 11:17:00,581:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 191 not found\n",
      "[WARNING] [2023-02-07 11:17:00,582:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 277 not found\n",
      "[WARNING] [2023-02-07 11:17:00,583:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 563 not found\n",
      "[WARNING] [2023-02-07 11:17:00,583:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 124 not found\n",
      "[WARNING] [2023-02-07 11:17:00,584:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 121 not found\n",
      "[WARNING] [2023-02-07 11:17:00,584:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 683 not found\n",
      "[WARNING] [2023-02-07 11:17:00,584:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 352 not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-02-07 11:17:00,584:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 434 not found\n",
      "[WARNING] [2023-02-07 11:17:00,584:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 199 not found\n",
      "[WARNING] [2023-02-07 11:17:00,584:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 445 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 318 not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 363 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 173 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 647 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 412 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 131 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 494 not found\n",
      "[WARNING] [2023-02-07 11:17:00,585:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 500 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 37 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 17 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 480 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 524 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 529 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 403 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 628 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 288 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 298 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 171 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 375 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 59 not found\n",
      "[WARNING] [2023-02-07 11:17:00,586:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 553 not found\n",
      "[WARNING] [2023-02-07 11:17:00,587:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 621 not found\n",
      "[WARNING] [2023-02-07 11:17:00,587:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 85 not found\n",
      "[WARNING] [2023-02-07 11:17:00,588:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 291 not found\n",
      "[WARNING] [2023-02-07 11:17:00,588:Client-AutoMLSMBO(1)::8d1e93df-a6d0-11ed-8083-00155da455e5] Configuration 273 not found\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.641285\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:11\n",
      "[CaTabRa] New model #1 trained:\n",
      "    val_f1_macro: 0.641285\n",
      "    train_f1_macro: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:11\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.698102\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:37\n",
      "[CaTabRa] New model #2 trained:\n",
      "    val_f1_macro: 0.698102\n",
      "    train_f1_macro: 1.000000\n",
      "    type: mlp\n",
      "    total_elapsed_time: 00:36\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 01:21\n",
      "[CaTabRa] New model #3 trained:\n",
      "    val_f1_macro: 0.761772\n",
      "    train_f1_macro: 0.917106\n",
      "    type: mlp\n",
      "    total_elapsed_time: 01:21\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 01:23\n",
      "[CaTabRa] New model #4 trained:\n",
      "    val_f1_macro: 0.319453\n",
      "    train_f1_macro: 0.904445\n",
      "    type: liblinear_svc\n",
      "    total_elapsed_time: 01:22\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 01:26\n",
      "[CaTabRa] New model #5 trained:\n",
      "    val_f1_macro: 0.700602\n",
      "    train_f1_macro: 0.869776\n",
      "    type: mlp\n",
      "    total_elapsed_time: 01:25\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 01:36\n",
      "[CaTabRa] New model #6 trained:\n",
      "    val_f1_macro: 0.593701\n",
      "    train_f1_macro: 0.990705\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 01:36\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 01:54\n",
      "[CaTabRa] New model #7 trained:\n",
      "    val_f1_macro: 0.020042\n",
      "    train_f1_macro: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 01:53\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 01:59\n",
      "[CaTabRa] New model #8 trained:\n",
      "    val_f1_macro: 0.673939\n",
      "    train_f1_macro: 1.000000\n",
      "    type: k_nearest_neighbors\n",
      "    total_elapsed_time: 01:59\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 02:08\n",
      "[CaTabRa] New model #9 trained:\n",
      "    val_f1_macro: 0.640255\n",
      "    train_f1_macro: 0.907360\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 02:07\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 02:17\n",
      "[CaTabRa] New model #10 trained:\n",
      "    val_f1_macro: 0.594273\n",
      "    train_f1_macro: 0.984806\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 02:16\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 02:27\n",
      "[CaTabRa] New model #11 trained:\n",
      "    val_f1_macro: 0.603230\n",
      "    train_f1_macro: 1.000000\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 02:27\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 02:33\n",
      "[CaTabRa] New model #12 trained:\n",
      "    val_f1_macro: 0.724957\n",
      "    train_f1_macro: 0.926656\n",
      "    type: mlp\n",
      "    total_elapsed_time: 02:33\n",
      "[CaTabRa] New model #13 trained:\n",
      "    val_f1_macro: 0.215699\n",
      "    train_f1_macro: 0.662193\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 02:42\n",
      "[CaTabRa] New model #14 trained:\n",
      "    val_f1_macro: 0.593483\n",
      "    train_f1_macro: 0.984792\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 02:46\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_f1_macro: 0.761772\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 02:52\n",
      "[CaTabRa] New model #15 trained:\n",
      "    val_f1_macro: 0.690480\n",
      "    train_f1_macro: 0.715259\n",
      "    type: mlp\n",
      "    total_elapsed_time: 02:52\n",
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 15\n",
      "    ensemble_val_f1_macro: 0.7617723444629978\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type Autoencoder\n",
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "Iteration 1, loss = 0.05982325\n",
      "Iteration 2, loss = 0.03488524\n",
      "Iteration 3, loss = 0.02117650\n",
      "Iteration 4, loss = 0.01949050\n",
      "Iteration 5, loss = 0.01914386\n",
      "Iteration 6, loss = 0.01906342\n",
      "Iteration 7, loss = 0.01904390\n",
      "Iteration 8, loss = 0.01904470\n",
      "Iteration 9, loss = 0.01901837\n",
      "Iteration 10, loss = 0.01901736\n",
      "Iteration 11, loss = 0.01899080\n",
      "Iteration 12, loss = 0.01898463\n",
      "Iteration 13, loss = 0.01898274\n",
      "Iteration 14, loss = 0.01896644\n",
      "Iteration 15, loss = 0.01896694\n",
      "Iteration 16, loss = 0.01898501\n",
      "Iteration 17, loss = 0.01896577\n",
      "Iteration 18, loss = 0.01895877\n",
      "Iteration 19, loss = 0.01894492\n",
      "Iteration 20, loss = 0.01894275\n",
      "Iteration 21, loss = 0.01893161\n",
      "Iteration 22, loss = 0.01893052\n",
      "Iteration 23, loss = 0.01892016\n",
      "Iteration 24, loss = 0.01892147\n",
      "Iteration 25, loss = 0.01891416\n",
      "Iteration 26, loss = 0.01892668\n",
      "Iteration 27, loss = 0.01892885\n",
      "Iteration 28, loss = 0.01891607\n",
      "Iteration 29, loss = 0.01890401\n",
      "Iteration 30, loss = 0.01889755\n",
      "Iteration 31, loss = 0.01891291\n",
      "Iteration 32, loss = 0.01894366\n",
      "Iteration 33, loss = 0.01892826\n",
      "Iteration 34, loss = 0.01890775\n",
      "Iteration 35, loss = 0.01891401\n",
      "Iteration 36, loss = 0.01889082\n",
      "Iteration 37, loss = 0.01889566\n",
      "Iteration 38, loss = 0.01888600\n",
      "Iteration 39, loss = 0.01888517\n",
      "Iteration 40, loss = 0.01887266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41, loss = 0.01887094\n",
      "Iteration 42, loss = 0.01887194\n",
      "Iteration 43, loss = 0.01888870\n",
      "Iteration 44, loss = 0.01891678\n",
      "Iteration 45, loss = 0.01890816\n",
      "Iteration 46, loss = 0.01889278\n",
      "Iteration 47, loss = 0.01886188\n",
      "Iteration 48, loss = 0.01885999\n",
      "Iteration 49, loss = 0.01885912\n",
      "Iteration 50, loss = 0.01886987\n",
      "Iteration 51, loss = 0.01887337\n",
      "Iteration 52, loss = 0.01885332\n",
      "Iteration 53, loss = 0.01883346\n",
      "Iteration 54, loss = 0.01887909\n",
      "Iteration 55, loss = 0.01889231\n",
      "Iteration 56, loss = 0.01883884\n",
      "Training loss did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-02-07 11:20:40.127400\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:03:53.794327\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/multilabel_classification\n",
      "[CaTabRa] ### Evaluation started at 2023-02-07 11:20:40.130001\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    f1_macro @ 0.5: 0.9725546309829336\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    f1_macro @ 0.5: 0.3461939178627995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n",
      "No positive samples in y_true, true positive value should be meaningless and recall is set to 1 for all thresholds\n",
      "invalid value encountered in true_divide\n",
      "No positive samples in y_true, true positive value should be meaningless and recall is set to 1 for all thresholds\n",
      "invalid value encountered in true_divide\n",
      "No positive samples in y_true, true positive value should be meaningless and recall is set to 1 for all thresholds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Evaluation finished at 2023-02-07 11:21:24.398684\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:44.268683\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/multilabel_classification/eval\n"
     ]
    }
   ],
   "source": [
    "analyze(\n",
    "    X_multilabel,             # table to analyze; can also be the path to a CSV/Excel/HDF5 file\n",
    "    classify=['Beach', 'Sunset', 'FallFoliage', 'Field', 'Mountain', 'Urban'],\n",
    "    split='train',            # name of column containing information about the train-test split (optional)\n",
    "    time=3,                   # time budget for hyperparameter tuning, in minutes (optional)\n",
    "    out='multilabel_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242cadea",
   "metadata": {},
   "source": [
    "Note again how the performance metrics reported during training differ from those in binary- and multiclass classification. This is also reflected in the detailed performance reports in subdirectory `eval/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f07c4c",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194ea2e",
   "metadata": {},
   "source": [
    "Analyze data with one or more regression targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52c3e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "X_regression, y_regression = load_diabetes(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f421c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target labels to DataFrame\n",
    "X_regression['disease_progression'] = y_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a43b212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train- and test set by adding column with corresponding values\n",
    "# the name of the column is arbitrary; CaTabRa tries to \"guess\" which samples belong to which set based on the column name and -values\n",
    "X_regression['train'] = X_regression.index <= 0.8 * len(X_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "097bffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>disease_progression</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi  ...        s6  disease_progression  train\n",
       "0  0.038076  0.050680  0.061696  ... -0.017646                151.0   True\n",
       "1 -0.001882 -0.044642 -0.051474  ... -0.092204                 75.0   True\n",
       "2  0.085299  0.050680  0.044451  ... -0.025930                141.0   True\n",
       "3 -0.089063 -0.044642 -0.011595  ... -0.009362                206.0   True\n",
       "4  0.005383 -0.044642 -0.036385  ... -0.046641                135.0   True\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_regression.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb98ac8",
   "metadata": {},
   "source": [
    "Function `analyze()` is again called as before, the only difference being that keyword argument `classify` is replaced by `regress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35085b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] ### Analysis started at 2023-02-07 11:26:30.909830\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Using AutoML-backend auto-sklearn for regression\n",
      "[CaTabRa] Successfully loaded the following auto-sklearn add-on module(s): xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.346560\n",
      "    n_constituent_models: 1\n",
      "    total_elapsed_time: 00:14\n",
      "[CaTabRa] New model #1 trained:\n",
      "    val_r2: 0.346560\n",
      "    val_mean_absolute_error: 47.753839\n",
      "    val_mean_squared_error: 3699.549517\n",
      "    train_r2: 0.924566\n",
      "    type: random_forest\n",
      "    total_elapsed_time: 00:14\n",
      "[CaTabRa] New model #2 trained:\n",
      "    val_r2: -0.000265\n",
      "    val_mean_absolute_error: 62.965668\n",
      "    val_mean_squared_error: 5663.151483\n",
      "    train_r2: 0.998678\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:15\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.347943\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:19\n",
      "[CaTabRa] New model #3 trained:\n",
      "    val_r2: 0.065712\n",
      "    val_mean_absolute_error: 60.908616\n",
      "    val_mean_squared_error: 5289.613941\n",
      "    train_r2: 0.997329\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:19\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.388678\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:21\n",
      "[CaTabRa] New model #4 trained:\n",
      "    val_r2: 0.378612\n",
      "    val_mean_absolute_error: 47.679539\n",
      "    val_mean_squared_error: 3518.081929\n",
      "    train_r2: 0.573299\n",
      "    type: ard_regression\n",
      "    total_elapsed_time: 00:21\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.397726\n",
      "    n_constituent_models: 2\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New model #5 trained:\n",
      "    val_r2: 0.368827\n",
      "    val_mean_absolute_error: 47.818353\n",
      "    val_mean_squared_error: 3573.482370\n",
      "    train_r2: 0.918655\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:22\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.399933\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:23\n",
      "[CaTabRa] New model #6 trained:\n",
      "    val_r2: 0.348328\n",
      "    val_mean_absolute_error: 47.907515\n",
      "    val_mean_squared_error: 3689.537293\n",
      "    train_r2: 0.922852\n",
      "    type: gradient_boosting\n",
      "    total_elapsed_time: 00:23\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.425789\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:24\n",
      "[CaTabRa] New model #7 trained:\n",
      "    val_r2: 0.415240\n",
      "    val_mean_absolute_error: 46.700819\n",
      "    val_mean_squared_error: 3310.708121\n",
      "    train_r2: 0.523863\n",
      "    type: sgd\n",
      "    total_elapsed_time: 00:24\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.425789\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:25\n",
      "[CaTabRa] New model #8 trained:\n",
      "    val_r2: 0.401955\n",
      "    val_mean_absolute_error: 47.683143\n",
      "    val_mean_squared_error: 3385.920689\n",
      "    train_r2: 0.547418\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:25\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.425789\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:34\n",
      "[CaTabRa] New model #9 trained:\n",
      "    val_r2: 0.330392\n",
      "    val_mean_absolute_error: 48.786826\n",
      "    val_mean_squared_error: 3791.084115\n",
      "    train_r2: 1.000000\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:34\n",
      "[CaTabRa] New model #10 trained:\n",
      "    val_r2: -0.000265\n",
      "    val_mean_absolute_error: 62.965668\n",
      "    val_mean_squared_error: 5663.151483\n",
      "    train_r2: 0.999580\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:35\n",
      "[CaTabRa] New model #11 trained:\n",
      "    val_r2: -0.000265\n",
      "    val_mean_absolute_error: 62.965668\n",
      "    val_mean_squared_error: 5663.151483\n",
      "    train_r2: 0.992597\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:36\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.425789\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:37\n",
      "[CaTabRa] New model #12 trained:\n",
      "    val_r2: 0.354427\n",
      "    val_mean_absolute_error: 47.265859\n",
      "    val_mean_squared_error: 3655.010389\n",
      "    train_r2: 1.000000\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:37\n",
      "[CaTabRa] New model #13 trained:\n",
      "    val_r2: -0.000265\n",
      "    val_mean_absolute_error: 62.965668\n",
      "    val_mean_squared_error: 5663.151483\n",
      "    train_r2: 0.999705\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:38\n",
      "[CaTabRa] New model #14 trained:\n",
      "    val_r2: -0.000265\n",
      "    val_mean_absolute_error: 62.965668\n",
      "    val_mean_squared_error: 5663.151483\n",
      "    train_r2: 0.999234\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:38\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.425789\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:40\n",
      "[CaTabRa] New model #15 trained:\n",
      "    val_r2: 0.374720\n",
      "    val_mean_absolute_error: 46.745134\n",
      "    val_mean_squared_error: 3540.116141\n",
      "    train_r2: 0.977903\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:39\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.437003\n",
      "    n_constituent_models: 5\n",
      "    total_elapsed_time: 00:41\n",
      "[CaTabRa] New model #16 trained:\n",
      "    val_r2: 0.125783\n",
      "    val_mean_absolute_error: 57.840272\n",
      "    val_mean_squared_error: 4949.511448\n",
      "    train_r2: 0.999744\n",
      "    type: gaussian_process\n",
      "    total_elapsed_time: 00:41\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.425789\n",
      "    n_constituent_models: 3\n",
      "    total_elapsed_time: 00:42\n",
      "[CaTabRa] New model #17 trained:\n",
      "    val_r2: 0.387407\n",
      "    val_mean_absolute_error: 46.685701\n",
      "    val_mean_squared_error: 3468.285643\n",
      "    train_r2: 0.846457\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:42\n",
      "[CaTabRa] New model #18 trained:\n",
      "    val_r2: 0.196697\n",
      "    val_mean_absolute_error: 50.261620\n",
      "    val_mean_squared_error: 4548.019091\n",
      "    train_r2: 0.645442\n",
      "    type: libsvm_svr\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.428171\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New model #19 trained:\n",
      "    val_r2: 0.373981\n",
      "    val_mean_absolute_error: 46.977856\n",
      "    val_mean_squared_error: 3544.300674\n",
      "    train_r2: 0.596925\n",
      "    type: libsvm_svr\n",
      "    total_elapsed_time: 00:43\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.428171\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:44\n",
      "[CaTabRa] New model #20 trained:\n",
      "    val_r2: 0.384921\n",
      "    val_mean_absolute_error: 48.585789\n",
      "    val_mean_squared_error: 3482.360456\n",
      "    train_r2: 0.528625\n",
      "    type: liblinear_svr\n",
      "    total_elapsed_time: 00:44\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.427500\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:45\n",
      "[CaTabRa] New model #21 trained:\n",
      "    val_r2: 0.398428\n",
      "    val_mean_absolute_error: 46.894167\n",
      "    val_mean_squared_error: 3405.887542\n",
      "    train_r2: 0.560726\n",
      "    type: sgd\n",
      "    total_elapsed_time: 00:45\n",
      "[CaTabRa] New model #22 trained:\n",
      "    val_r2: 0.152500\n",
      "    val_mean_absolute_error: 56.274715\n",
      "    val_mean_squared_error: 4798.245744\n",
      "    train_r2: 0.188230\n",
      "    type: libsvm_svr\n",
      "    total_elapsed_time: 00:45\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.427500\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:46\n",
      "[CaTabRa] New model #23 trained:\n",
      "    val_r2: 0.392710\n",
      "    val_mean_absolute_error: 47.980951\n",
      "    val_mean_squared_error: 3438.262290\n",
      "    train_r2: 0.521770\n",
      "    type: ard_regression\n",
      "    total_elapsed_time: 00:46\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.426474\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:47\n",
      "[CaTabRa] New model #24 trained:\n",
      "    val_r2: 0.412140\n",
      "    val_mean_absolute_error: 46.539725\n",
      "    val_mean_squared_error: 3328.259648\n",
      "    train_r2: 0.536904\n",
      "    type: ard_regression\n",
      "    total_elapsed_time: 00:47\n",
      "[CaTabRa] New model #25 trained:\n",
      "    val_r2: 0.226133\n",
      "    val_mean_absolute_error: 50.241453\n",
      "    val_mean_squared_error: 4381.364850\n",
      "    train_r2: 0.648969\n",
      "    type: k_nearest_neighbors\n",
      "    total_elapsed_time: 00:50\n",
      "[CaTabRa] New model #26 trained:\n",
      "    val_r2: 0.270252\n",
      "    val_mean_absolute_error: 52.848647\n",
      "    val_mean_squared_error: 4131.579680\n",
      "    train_r2: 0.338830\n",
      "    type: extra_trees\n",
      "    total_elapsed_time: 00:51\n",
      "[CaTabRa] New ensemble fitted:\n",
      "    ensemble_val_r2: 0.426118\n",
      "    n_constituent_models: 4\n",
      "    total_elapsed_time: 00:52\n",
      "[CaTabRa] New model #27 trained:\n",
      "    val_r2: 0.374823\n",
      "    val_mean_absolute_error: 48.787595\n",
      "    val_mean_squared_error: 3539.532322\n",
      "    train_r2: 0.537110\n",
      "    type: libsvm_svr\n",
      "    total_elapsed_time: 00:52\n",
      "[CaTabRa] New model #28 trained:\n",
      "    val_r2: 0.292769\n",
      "    val_mean_absolute_error: 49.361707\n",
      "    val_mean_squared_error: 4004.093698\n",
      "    train_r2: 0.991042\n",
      "    type: adaboost\n",
      "    total_elapsed_time: 00:57\n",
      "[CaTabRa] Final training statistics:\n",
      "    n_models_trained: 28\n",
      "    ensemble_val_r2: 0.4261181505761964\n",
      "[CaTabRa] Creating shap explainer\n",
      "[CaTabRa] Initialized out-of-distribution detector of type Autoencoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CaTabRa] Fitting out-of-distribution detector...\n",
      "Iteration 1, loss = 0.25534312\n",
      "Iteration 2, loss = 0.14401352\n",
      "Iteration 3, loss = 0.09340346\n",
      "Iteration 4, loss = 0.06996843\n",
      "Iteration 5, loss = 0.05760558\n",
      "Iteration 6, loss = 0.05068051\n",
      "Iteration 7, loss = 0.04561450\n",
      "Iteration 8, loss = 0.04126809\n",
      "Iteration 9, loss = 0.03752003\n",
      "Iteration 10, loss = 0.03445358\n",
      "Iteration 11, loss = 0.03203054\n",
      "Iteration 12, loss = 0.03026330\n",
      "Iteration 13, loss = 0.02909024\n",
      "Iteration 14, loss = 0.02833517\n",
      "Iteration 15, loss = 0.02799340\n",
      "Iteration 16, loss = 0.02790263\n",
      "Iteration 17, loss = 0.02800053\n",
      "Iteration 18, loss = 0.02816715\n",
      "Iteration 19, loss = 0.02833172\n",
      "Iteration 20, loss = 0.02843938\n",
      "Iteration 21, loss = 0.02845107\n",
      "Iteration 22, loss = 0.02837497\n",
      "Iteration 23, loss = 0.02823050\n",
      "Iteration 24, loss = 0.02807415\n",
      "Iteration 25, loss = 0.02792351\n",
      "Iteration 26, loss = 0.02779502\n",
      "Iteration 27, loss = 0.02770411\n",
      "Iteration 28, loss = 0.02762860\n",
      "Iteration 29, loss = 0.02758793\n",
      "Iteration 30, loss = 0.02757642\n",
      "Iteration 31, loss = 0.02758407\n",
      "Iteration 32, loss = 0.02758500\n",
      "Iteration 33, loss = 0.02758951\n",
      "Iteration 34, loss = 0.02760158\n",
      "Iteration 35, loss = 0.02759723\n",
      "Iteration 36, loss = 0.02758483\n",
      "Iteration 37, loss = 0.02759659\n",
      "Iteration 38, loss = 0.02757972\n",
      "Iteration 39, loss = 0.02757239\n",
      "Iteration 40, loss = 0.02757055\n",
      "Iteration 41, loss = 0.02756013\n",
      "Iteration 42, loss = 0.02755758\n",
      "Iteration 43, loss = 0.02755460\n",
      "Iteration 44, loss = 0.02755353\n",
      "Iteration 45, loss = 0.02754807\n",
      "Iteration 46, loss = 0.02755253\n",
      "Iteration 47, loss = 0.02755638\n",
      "Iteration 48, loss = 0.02755479\n",
      "Iteration 49, loss = 0.02755098\n",
      "Iteration 50, loss = 0.02755119\n",
      "Iteration 51, loss = 0.02755607\n",
      "Iteration 52, loss = 0.02755033\n",
      "Iteration 53, loss = 0.02755640\n",
      "Iteration 54, loss = 0.02755645\n",
      "Iteration 55, loss = 0.02757725\n",
      "Iteration 56, loss = 0.02755438\n",
      "Iteration 57, loss = 0.02754601\n",
      "Iteration 58, loss = 0.02755765\n",
      "Iteration 59, loss = 0.02755344\n",
      "Iteration 60, loss = 0.02754537\n",
      "Iteration 61, loss = 0.02755214\n",
      "Iteration 62, loss = 0.02755442\n",
      "Iteration 63, loss = 0.02754713\n",
      "Iteration 64, loss = 0.02756334\n",
      "Iteration 65, loss = 0.02755607\n",
      "Iteration 66, loss = 0.02756124\n",
      "Iteration 67, loss = 0.02756447\n",
      "Iteration 68, loss = 0.02754924\n",
      "Iteration 69, loss = 0.02755174\n",
      "Iteration 70, loss = 0.02755024\n",
      "Iteration 71, loss = 0.02754852\n",
      "Iteration 72, loss = 0.02754915\n",
      "Iteration 73, loss = 0.02755081\n",
      "Iteration 74, loss = 0.02755050\n",
      "Iteration 75, loss = 0.02755403\n",
      "Iteration 76, loss = 0.02755376\n",
      "Iteration 77, loss = 0.02754660\n",
      "Training loss did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "[CaTabRa] Out-of-distribution detector fitted.\n",
      "[CaTabRa] ### Analysis finished at 2023-02-07 11:27:39.991968\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:01:09.082138\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/regression\n",
      "[CaTabRa] ### Evaluation started at 2023-02-07 11:27:39.994605\n",
      "[CaTabRa] Predicting out-of-distribution samples.\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Saving descriptive statistics completed\n",
      "[CaTabRa] Evaluation results for train:\n",
      "    r2: 0.5506768595078299\n",
      "    mean_absolute_error: 41.25392512008969\n",
      "    mean_squared_error: 2602.6718459220265\n",
      "[CaTabRa] Evaluation results for not_train:\n",
      "    r2: 0.5397624701720876\n",
      "    mean_absolute_error: 43.66707866842096\n",
      "    mean_squared_error: 2978.0636912322097\n",
      "[CaTabRa] ### Evaluation finished at 2023-02-07 11:27:41.190400\n",
      "[CaTabRa] ### Elapsed time: 0 days 00:00:01.195795\n",
      "[CaTabRa] ### Output saved in /mnt/c/Users/amaletzk/Documents/CaTabRa/catabra/examples/regression/eval\n"
     ]
    }
   ],
   "source": [
    "analyze(\n",
    "    X_regression,             # table to analyze; can also be the path to a CSV/Excel/HDF5 file\n",
    "    regress=['disease_progression'],   # name(s) of target column(s)\n",
    "    split='train',            # name of column containing information about the train-test split (optional)\n",
    "    time=1,                   # time budget for hyperparameter tuning, in minutes (optional)\n",
    "    out='regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14240c",
   "metadata": {},
   "source": [
    "The performance metrics reported during training differ from those in classification. This is also reflected in the detailed performance reports in subdirectory `eval/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

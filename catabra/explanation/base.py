from typing import Optional, Callable, Dict, List
from pathlib import Path
import importlib
import numpy as np
import pandas as pd


class TransformationExplainer:

    _factories = []

    @staticmethod
    def register_factory(name: str, func, errors: str = 'raise'):
        i = [j for j, (n, _) in enumerate(TransformationExplainer._factories) if name == n]
        if i:
            if errors == 'raise':
                raise ValueError(f'Transformation explainer factory with name "{name}" already exists.')
            elif errors == 'update':
                TransformationExplainer._factories[i[0]] = (name, func)
            elif errors == 'replace':
                del TransformationExplainer._factories[i[0]]
                TransformationExplainer._factories.insert(0, (name, func))
        else:
            TransformationExplainer._factories.insert(0, (name, func))

    @staticmethod
    def make(obj, params=None) -> Optional['TransformationExplainer']:
        if all(hasattr(obj, attr)
               for attr in ('fit', 'transform', 'fit_forward', 'forward', 'backward', 'backward_global')):
            return obj

        for _, func in TransformationExplainer._factories:
            out = func(obj, params=params)
            if out is not obj:
                return out

        raise RuntimeError(f'Object of type {type(obj)} cannot be converted into a transformation explainer.')

    def __init__(self, transformer=None, params=None):
        if params is not None:
            assert params.get('class_name', self.__class__.__name__) == self.__class__.__name__
        self._transformer = transformer

    @property
    def transformer(self):
        return self._transformer

    @property
    def params_(self) -> dict:
        """
        Get all params obtained from fitting the explainer to data in method `fit_forward()`, and which can be passed
        to `__init__()`.
        """
        return dict(class_name=self.__class__.__name__)

    def fit(self, x, y=None):
        # only to implement the standard sklearn API, which makes it possible to combine individual explainers in
        # pipelines and similar compound transformations
        raise RuntimeError(f'Method fit() of class {self.__class__.__name__} cannot be called.')

    def transform(self, x):
        return self._transformer.transform(x)

    def fit_forward(self, x, y):
        """
        Fit this explainer to training data, and transform the data by applying the underlying transformation.
        `forward()` is implicitly called on `x` as well, meaning that invoking `backward()` immediately afterwards is
        possible and refers to the given samples `x`.
        :param x: Features, array-like of shape `(n_samples, n_features_in)`.
        :param y: Labels, array-like of shape `(n_samples, n_labels)` or `(n_samples,)`.
        :return: The transformed features, array-like of shape `(n_samples, n_features_out)`.
        """
        raise NotImplementedError()

    def forward(self, x):
        """
        Transform `x` by applying the underlying transformation, and record all intermediate values needed for
        back-propagating explanations generated by downstream explanation methods.
        :param x: Data to transform (and later explain), array-like of shape `(n_samples, n_features_in)`.
        `n_features_in` must be the same as in the data this explainer instance was fitted on.
        :return: Transformed data, array-like of shape `(n_samples, n_features_out)`.
        """
        raise NotImplementedError()

    def backward(self, s: np.ndarray) -> np.ndarray:
        """
        Back-propagate local explanations from output to input.
        :param s: Explanations (feature importance scores) generated downstream for the last `x` method `forward()` was
        applied to. Array of shape `(*dims, n_samples, n_features_out)`, where `n_samples` must be as in the last
        invocation of `forward()`.
        :return: Explanations, array of shape `(*dims, n_samples, n_features_in)`.

        **Note**: In contrast to method `forward()`, this method expects plain Numpy arrays as input and returns plain
        Numpy arrays.
        """
        raise NotImplementedError()

    def backward_global(self, s: np.ndarray) -> np.ndarray:
        """
        Back-propagate global explanations from output to input.
        :param s: Global explanations (feature importance scores) generated by downstream explanation methods.
        Array of shape `(*dims, n_features_out)`.
        :return: Explanations, array of shape `(*dims, n_features_in)`.

        **Note**: In contrast to method `forward()`, this method expects plain Numpy arrays as input and returns plain
        Numpy arrays.
        """
        raise NotImplementedError()


class IdentityTransformationExplainer(TransformationExplainer):

    def __init__(self, transformer=None, params=None):
        super(IdentityTransformationExplainer, self).__init__(transformer=transformer, params=params)
        self._transform_func = getattr(self._transformer, 'transform', None)

    def transform(self, x):
        return x if self._transform_func is None else self._transform_func(x)

    def fit_forward(self, x, y):
        return self.forward(x)

    def forward(self, x):
        return self.transform(x)

    def backward(self, s):
        return s

    def backward_global(self, s):
        return s


class EnsembleExplainer:
    __registered = {}

    @staticmethod
    def register(name: str, factory: Callable[..., 'EnsembleExplainer']):
        """
        Register a new ensemble explainer factory.
        :param name: The name of the ensemble explainer.
        :param factory: The factory, a function mapping argument-dicts to instances of class `EnsembleExplainer` (or
        subclasses thereof).
        """
        EnsembleExplainer.__registered[name] = factory

    @staticmethod
    def get(name: str, **kwargs) -> Optional['EnsembleExplainer']:
        factory = EnsembleExplainer.__registered.get(name)
        return factory if factory is None else factory(**kwargs)

    @classmethod
    def name(cls) -> str:
        raise NotImplementedError()

    @classmethod
    def global_behavior(cls) -> dict:
        """
        Description of the behavior of method `explain_global()`, especially w.r.t. parameter `x`. Dict with keys
        * "accepts_x": True if `x` can be provided.
        * "requires_x": True if `x` must be provided. If False but "accepts_x" is True, the global behavior differs
            depending on whether `x` is provided. "requires_x" can only be True if "accepts_x" is True as well.
        * "mean_of_local": True if global explanations are the mean of the individual local explanations, if `x` is
            provided. If True, it might be better to call method `explain()` instead of `explain_global()`, since the
            computational effort is identical.
        :return: Dict, as described above.
        """
        raise NotImplementedError()

    def __init__(self, ensemble: 'FittedEnsemble' = None, config: Optional[dict] = None,
                 feature_names: Optional[list] = None, target_names: Optional[list] = None,
                 x: Optional[pd.DataFrame] = None, y: Optional[pd.DataFrame] = None, params=None):
        """
        Initialize an EnsembleExplainer for explaining the given ensemble, or constituents of it.
        :param ensemble: The ensemble to explain, an instance of FittedEnsemble.
        :param config: Config dict, optional.
        :param feature_names: List of feature names, optional. None defaults to `range(n_features)`, where `n_features`
        is determined from `x`.
        :param target_names: List of target names, optional. In case of regression this is the list of target
        variables, in case of binary classification this is the singleton list with the sole target variable, and in
        multiclass- and multilabel classification this is the list of classes. None defaults to `range(n_targets)`,
        where `n_targets` is determined from `y`.
        :param x: Training data, which is required by some explanation methods (e.g., SHAP).
        :param y: Labels of `x`, optional.
        :param params: Params obtained from a previous instantiation of an ensemble explainer of this type on
        `ensemble`. If given, neither `feature_names`, `target_names`, `x` nor `y` may be provided.
        """
        if not (params is None or (feature_names is None and target_names is None and x is None and y is None)):
            raise ValueError('If params is given, feature_names, target_names, x and y must be None.')
        self.config: dict = config or {}

    @property
    def params_(self) -> dict:
        """
        Get all params necessary for instantiating this EnsembleExplainer via parameter `params`.
        """
        raise NotImplementedError()

    def explain(self, x: pd.DataFrame, jobs: int = 1, batch_size: Optional[int] = None, model_id=None,
                show_progress: bool = False) -> dict:
        """
        Explain the ensemble, or some of its constituent models (pipelines), on a set of samples.
        :param x: The samples, a DataFrame with the same columns as the ensemble was trained on.
        :param jobs: The number of jobs to use.
        :param batch_size: The batch size to use.
        :param model_id: The ID(s) of the model(s) to explain, or None to explain all models in the ensemble.
        :param show_progress: Whether to display a progress bar.
        :return: Dict with 1-2 levels of nesting. The keys in the outer dict are model-IDs (possibly including
        "__ensemble__"), and the keys in the inner dicts (if any) are arbitrary and usually depend on the prediction
        task and the explanation backend. Ultimately, the values are DataFrames with the same row index as `x` and
        columns corresponding to `feature_names`, containing feature importance scores. Note that the result consists
        entirely of floating point values, even if `x` has categorical or other columns.
        """
        raise NotImplementedError()

    def explain_global(self, x: Optional[pd.DataFrame] = None, sample_weight: Optional[np.ndarray] = None,
                       jobs: int = 1, batch_size: Optional[int] = None, model_id=None,
                       show_progress: bool = False) -> dict:
        """
        Explain the ensemble, or some of its constituent models (pipelines), globally.
        :param x: Samples, optional, a DataFrame with the same columns as the ensemble was trained on.
        Call method `global_behavior()` to see whether this argument is accepted or required (depends on the backend).
        :param sample_weight: Sample weight. Ignored if `x` is None.
        :param jobs: The number of jobs to use.
        :param batch_size: The batch size to use.
        :param model_id: The ID(s) of the model(s) to explain, or None to explain all models in the ensemble.
        :param show_progress: Whether to display a progress bar.
        :return: Dict whose keys are model-IDs (possibly including "__ensemble__"), and whose values are Series or
        DataFrames with feature importance scores. In either case, the row index equals `feature_names`, and the
        columns of DataFrames can be arbitrary and usually depend on the prediction task and the explanation backend.
        """
        raise NotImplementedError()

    def aggregate_explanations(self, explanations: Dict, mapping: Dict[str, List[str]]):
        raise NotImplementedError()

    def aggregate_explanations_global(self, explanations: pd.DataFrame, mapping: Dict[str, List[str]]):
        raise NotImplementedError()

    def aggregate_features(self, features: pd.DataFrame, mapping: Dict[str, List[str]]):
        raise NotImplementedError()

    @classmethod
    def get_versions(cls) -> dict:
        """
        Get the versions of all key packages and libraries this explanation backend depends upon.
        :return: Dict whose keys are package names and whose values are version strings.
        """
        raise NotImplementedError()


# load explanation backends
for _d in Path(__file__).parent.iterdir():
    if _d.is_dir() and (_d / '__init__.py').exists():
        importlib.import_module('.' + _d.stem, package=__package__)


# Paradigm for explaining a pipeline `model` of a FittedEnsemble
#
# setup:
# >>> preprocessing_explainer = TransformationExplainer.make(transformation=model.preprocessing)
# >>> x_train = preprocessing_explainer.fit_forward(x_train, y_train)
#
# local explanations for `x_test`:
# >>> x_test_pp = preprocessing_estimator.forward(x_test)
# >>> explanation = func(x_test_pp)
# >>> explanation = preprocessing_explainer.backward(explanation)
#
# global explanations:
# >>> explanation = func_global()
# >>> explanation = preprocessing_explainer.backward_global(explanation)


# Paradigm for explaining data `(x, y)` after applying some preprocessing steps `preprocessing`:
# >>> preprocessing_explainer = TransformationExplainer.make(transformation=preprocessing)
# >>> x_pp = preprocessing_explainer.fit_forward(x, y)`
# >>> explanation = func(x_pp, y)
# >>> explanation = preprocessing_explainer.backward(explanation)       # or `backward_global(explanation)`
